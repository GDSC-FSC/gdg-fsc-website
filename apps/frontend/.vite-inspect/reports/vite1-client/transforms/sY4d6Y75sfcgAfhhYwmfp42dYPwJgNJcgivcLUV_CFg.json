{
  "resolvedId": "/home/wombocombo/github/wrk/gdg-fsc-website/node_modules/effect/dist/esm/internal/stm/tMap.js",
  "transforms": [
    {
      "name": "__load__",
      "result": "import * as RA from \"../../Array.js\";\nimport * as Chunk from \"../../Chunk.js\";\nimport * as Equal from \"../../Equal.js\";\nimport { dual, pipe } from \"../../Function.js\";\nimport * as Hash from \"../../Hash.js\";\nimport * as HashMap from \"../../HashMap.js\";\nimport * as Option from \"../../Option.js\";\nimport { hasProperty } from \"../../Predicate.js\";\nimport * as STM from \"../../STM.js\";\nimport * as core from \"./core.js\";\nimport * as stm from \"./stm.js\";\nimport * as tArray from \"./tArray.js\";\nimport * as tRef from \"./tRef.js\";\n/** @internal */\nconst TMapSymbolKey = \"effect/TMap\";\n/** @internal */\nexport const TMapTypeId = /*#__PURE__*/Symbol.for(TMapSymbolKey);\nconst tMapVariance = {\n  /* c8 ignore next */\n  _K: _ => _,\n  /* c8 ignore next */\n  _V: _ => _\n};\n/** @internal */\nclass TMapImpl {\n  tBuckets;\n  tSize;\n  [TMapTypeId] = tMapVariance;\n  constructor(tBuckets, tSize) {\n    this.tBuckets = tBuckets;\n    this.tSize = tSize;\n  }\n}\nconst isTMap = u => hasProperty(u, TMapTypeId);\n/** @internal */\nconst InitialCapacity = 16;\nconst LoadFactor = 0.75;\n/** @internal */\nconst nextPowerOfTwo = size => {\n  const n = -1 >>> Math.clz32(size - 1);\n  return n < 0 ? 1 : n + 1;\n};\n/** @internal */\nconst hash = key => {\n  const h = Hash.hash(key);\n  return h ^ h >>> 16;\n};\n/** @internal */\nconst indexOf = (k, capacity) => hash(k) & capacity - 1;\n/** @internal */\nconst allocate = (capacity, data) => {\n  const buckets = Array.from({\n    length: capacity\n  }, () => Chunk.empty());\n  const distinct = new Map(data);\n  let size = 0;\n  for (const entry of distinct) {\n    const index = indexOf(entry[0], capacity);\n    buckets[index] = pipe(buckets[index], Chunk.prepend(entry));\n    size = size + 1;\n  }\n  return pipe(tArray.fromIterable(buckets), core.flatMap(buckets => pipe(tRef.make(buckets), core.flatMap(tBuckets => pipe(tRef.make(size), core.map(tSize => new TMapImpl(tBuckets, tSize)))))));\n};\n/** @internal */\nexport const empty = () => fromIterable([]);\n/** @internal */\nexport const find = /*#__PURE__*/dual(2, (self, pf) => findSTM(self, (key, value) => {\n  const option = pf(key, value);\n  if (Option.isSome(option)) {\n    return core.succeed(option.value);\n  }\n  return core.fail(Option.none());\n}));\n/** @internal */\nexport const findSTM = /*#__PURE__*/dual(2, (self, f) => reduceSTM(self, Option.none(), (acc, value, key) => Option.isNone(acc) ? core.matchSTM(f(key, value), {\n  onFailure: Option.match({\n    onNone: () => stm.succeedNone,\n    onSome: core.fail\n  }),\n  onSuccess: stm.succeedSome\n}) : STM.succeed(acc)));\n/** @internal */\nexport const findAll = /*#__PURE__*/dual(2, (self, pf) => findAllSTM(self, (key, value) => {\n  const option = pf(key, value);\n  if (Option.isSome(option)) {\n    return core.succeed(option.value);\n  }\n  return core.fail(Option.none());\n}));\n/** @internal */\nexport const findAllSTM = /*#__PURE__*/dual(2, (self, pf) => core.map(reduceSTM(self, Chunk.empty(), (acc, value, key) => core.matchSTM(pf(key, value), {\n  onFailure: Option.match({\n    onNone: () => core.succeed(acc),\n    onSome: core.fail\n  }),\n  onSuccess: a => core.succeed(Chunk.append(acc, a))\n})), a => Array.from(a)));\n/** @internal */\nexport const forEach = /*#__PURE__*/dual(2, (self, f) => reduceSTM(self, void 0, (_, value, key) => stm.asVoid(f(key, value))));\n/** @internal */\nexport const fromIterable = iterable => stm.suspend(() => {\n  const data = Chunk.fromIterable(iterable);\n  const capacity = data.length < InitialCapacity ? InitialCapacity : nextPowerOfTwo(data.length);\n  return allocate(capacity, data);\n});\n/** @internal */\nexport const get = /*#__PURE__*/dual(2, (self, key) => core.effect(journal => {\n  const buckets = tRef.unsafeGet(self.tBuckets, journal);\n  const index = indexOf(key, buckets.chunk.length);\n  const bucket = tRef.unsafeGet(buckets.chunk[index], journal);\n  return pipe(Chunk.findFirst(bucket, entry => Equal.equals(entry[0])(key)), Option.map(entry => entry[1]));\n}));\n/** @internal */\nexport const getOrElse = /*#__PURE__*/dual(3, (self, key, fallback) => core.map(get(self, key), Option.getOrElse(fallback)));\n/** @internal */\nexport const has = /*#__PURE__*/dual(2, (self, key) => core.map(get(self, key), Option.isSome));\n/** @internal */\nexport const isEmpty = self => core.map(tRef.get(self.tSize), size => size === 0);\n/** @internal */\nexport const keys = self => core.map(toReadonlyArray(self), RA.map(entry => entry[0]));\n/** @internal */\nexport const make = (...entries) => fromIterable(entries);\n/** @internal */\nexport const merge = /*#__PURE__*/dual(4, (self, key, value, f) => core.flatMap(get(self, key), Option.match({\n  onNone: () => stm.as(set(self, key, value), value),\n  onSome: v0 => {\n    const v1 = f(v0, value);\n    return stm.as(set(self, key, v1), v1);\n  }\n})));\n/** @internal */\nexport const reduce = /*#__PURE__*/dual(3, (self, zero, f) => core.effect(journal => {\n  const buckets = tRef.unsafeGet(self.tBuckets, journal);\n  let result = zero;\n  let index = 0;\n  while (index < buckets.chunk.length) {\n    const bucket = buckets.chunk[index];\n    const items = tRef.unsafeGet(bucket, journal);\n    result = Chunk.reduce(items, result, (acc, entry) => f(acc, entry[1], entry[0]));\n    index = index + 1;\n  }\n  return result;\n}));\n/** @internal */\nexport const reduceSTM = /*#__PURE__*/dual(3, (self, zero, f) => core.flatMap(toReadonlyArray(self), stm.reduce(zero, (acc, entry) => f(acc, entry[1], entry[0]))));\n/** @internal */\nexport const remove = /*#__PURE__*/dual(2, (self, key) => core.effect(journal => {\n  const buckets = tRef.unsafeGet(self.tBuckets, journal);\n  const index = indexOf(key, buckets.chunk.length);\n  const bucket = tRef.unsafeGet(buckets.chunk[index], journal);\n  const [toRemove, toRetain] = Chunk.partition(bucket, entry => Equal.equals(entry[1], key));\n  if (Chunk.isNonEmpty(toRemove)) {\n    const currentSize = tRef.unsafeGet(self.tSize, journal);\n    tRef.unsafeSet(buckets.chunk[index], toRetain, journal);\n    tRef.unsafeSet(self.tSize, currentSize - 1, journal);\n  }\n}));\n/** @internal */\nexport const removeAll = /*#__PURE__*/dual(2, (self, keys) => core.effect(journal => {\n  const iterator = keys[Symbol.iterator]();\n  let next;\n  while ((next = iterator.next()) && !next.done) {\n    const buckets = tRef.unsafeGet(self.tBuckets, journal);\n    const index = indexOf(next.value, buckets.chunk.length);\n    const bucket = tRef.unsafeGet(buckets.chunk[index], journal);\n    const [toRemove, toRetain] = Chunk.partition(bucket, entry => Equal.equals(next.value)(entry[0]));\n    if (Chunk.isNonEmpty(toRemove)) {\n      const currentSize = tRef.unsafeGet(self.tSize, journal);\n      tRef.unsafeSet(buckets.chunk[index], toRetain, journal);\n      tRef.unsafeSet(self.tSize, currentSize - 1, journal);\n    }\n  }\n}));\n/** @internal */\nexport const removeIf = /*#__PURE__*/dual(args => isTMap(args[0]), (self, predicate, options) => core.effect(journal => {\n  const discard = options?.discard === true;\n  const buckets = tRef.unsafeGet(self.tBuckets, journal);\n  const capacity = buckets.chunk.length;\n  const removed = [];\n  let index = 0;\n  let newSize = 0;\n  while (index < capacity) {\n    const bucket = tRef.unsafeGet(buckets.chunk[index], journal);\n    const iterator = bucket[Symbol.iterator]();\n    let next;\n    let newBucket = Chunk.empty();\n    while ((next = iterator.next()) && !next.done) {\n      const [k, v] = next.value;\n      if (!predicate(k, v)) {\n        newBucket = Chunk.prepend(newBucket, next.value);\n        newSize = newSize + 1;\n      } else {\n        if (!discard) {\n          removed.push([k, v]);\n        }\n      }\n    }\n    tRef.unsafeSet(buckets.chunk[index], newBucket, journal);\n    index = index + 1;\n  }\n  tRef.unsafeSet(self.tSize, newSize, journal);\n  if (!discard) {\n    return removed;\n  }\n}));\n/** @internal */\nexport const retainIf = /*#__PURE__*/dual(args => isTMap(args[0]), (self, predicate, options) => removeIf(self, (key, value) => !predicate(key, value), options));\n/** @internal */\nexport const set = /*#__PURE__*/dual(3, (self, key, value) => {\n  const resize = (journal, buckets) => {\n    const capacity = buckets.chunk.length;\n    const newCapacity = capacity << 1;\n    const newBuckets = Array.from({\n      length: newCapacity\n    }, () => Chunk.empty());\n    let index = 0;\n    while (index < capacity) {\n      const pairs = tRef.unsafeGet(buckets.chunk[index], journal);\n      const iterator = pairs[Symbol.iterator]();\n      let next;\n      while ((next = iterator.next()) && !next.done) {\n        const newIndex = indexOf(next.value[0], newCapacity);\n        newBuckets[newIndex] = Chunk.prepend(newBuckets[newIndex], next.value);\n      }\n      index = index + 1;\n    }\n    // insert new pair\n    const newIndex = indexOf(key, newCapacity);\n    newBuckets[newIndex] = Chunk.prepend(newBuckets[newIndex], [key, value]);\n    const newArray = [];\n    index = 0;\n    while (index < newCapacity) {\n      newArray[index] = new tRef.TRefImpl(newBuckets[index]);\n      index = index + 1;\n    }\n    const newTArray = new tArray.TArrayImpl(newArray);\n    tRef.unsafeSet(self.tBuckets, newTArray, journal);\n  };\n  return core.effect(journal => {\n    const buckets = tRef.unsafeGet(self.tBuckets, journal);\n    const capacity = buckets.chunk.length;\n    const index = indexOf(key, capacity);\n    const bucket = tRef.unsafeGet(buckets.chunk[index], journal);\n    const shouldUpdate = Chunk.some(bucket, entry => Equal.equals(key)(entry[0]));\n    if (shouldUpdate) {\n      const newBucket = Chunk.map(bucket, entry => Equal.equals(key)(entry[0]) ? [key, value] : entry);\n      tRef.unsafeSet(buckets.chunk[index], newBucket, journal);\n    } else {\n      const newSize = tRef.unsafeGet(self.tSize, journal) + 1;\n      tRef.unsafeSet(self.tSize, newSize, journal);\n      if (capacity * LoadFactor < newSize) {\n        resize(journal, buckets);\n      } else {\n        const newBucket = Chunk.prepend(bucket, [key, value]);\n        tRef.unsafeSet(buckets.chunk[index], newBucket, journal);\n      }\n    }\n  });\n});\n/** @internal */\nexport const setIfAbsent = /*#__PURE__*/dual(3, (self, key, value) => core.flatMap(get(self, key), Option.match({\n  onNone: () => set(self, key, value),\n  onSome: () => stm.void\n})));\n/** @internal */\nexport const size = self => tRef.get(self.tSize);\n/** @internal */\nexport const takeFirst = /*#__PURE__*/dual(2, (self, pf) => pipe(core.effect(journal => {\n  const buckets = tRef.unsafeGet(self.tBuckets, journal);\n  const capacity = buckets.chunk.length;\n  const size = tRef.unsafeGet(self.tSize, journal);\n  let result = Option.none();\n  let index = 0;\n  while (index < capacity && Option.isNone(result)) {\n    const bucket = tRef.unsafeGet(buckets.chunk[index], journal);\n    const recreate = Chunk.some(bucket, entry => Option.isSome(pf(entry[0], entry[1])));\n    if (recreate) {\n      const iterator = bucket[Symbol.iterator]();\n      let newBucket = Chunk.empty();\n      let next;\n      while ((next = iterator.next()) && !next.done && Option.isNone(result)) {\n        const option = pf(next.value[0], next.value[1]);\n        if (Option.isSome(option) && Option.isNone(result)) {\n          result = option;\n        } else {\n          newBucket = Chunk.prepend(newBucket, next.value);\n        }\n      }\n      tRef.unsafeSet(buckets.chunk[index], newBucket, journal);\n    }\n    index = index + 1;\n  }\n  if (Option.isSome(result)) {\n    tRef.unsafeSet(self.tSize, size - 1, journal);\n  }\n  return result;\n}), stm.collect(option => Option.isSome(option) ? Option.some(option.value) : Option.none())));\n/** @internal */\nexport const takeFirstSTM = /*#__PURE__*/dual(2, (self, pf) => pipe(findSTM(self, (key, value) => core.map(pf(key, value), a => [key, a])), stm.collect(option => Option.isSome(option) ? Option.some(option.value) : Option.none()), core.flatMap(entry => stm.as(remove(self, entry[0]), entry[1]))));\n/** @internal */\nexport const takeSome = /*#__PURE__*/dual(2, (self, pf) => pipe(core.effect(journal => {\n  const buckets = tRef.unsafeGet(self.tBuckets, journal);\n  const capacity = buckets.chunk.length;\n  const builder = [];\n  let newSize = 0;\n  let index = 0;\n  while (index < capacity) {\n    const bucket = tRef.unsafeGet(buckets.chunk[index], journal);\n    const recreate = Chunk.some(bucket, entry => Option.isSome(pf(entry[0], entry[1])));\n    if (recreate) {\n      const iterator = bucket[Symbol.iterator]();\n      let newBucket = Chunk.empty();\n      let next;\n      while ((next = iterator.next()) && !next.done) {\n        const option = pf(next.value[0], next.value[1]);\n        if (Option.isSome(option)) {\n          builder.push(option.value);\n        } else {\n          newBucket = Chunk.prepend(newBucket, next.value);\n          newSize = newSize + 1;\n        }\n      }\n      tRef.unsafeSet(buckets.chunk[index], newBucket, journal);\n    } else {\n      newSize = newSize + bucket.length;\n    }\n    index = index + 1;\n  }\n  tRef.unsafeSet(self.tSize, newSize, journal);\n  if (builder.length > 0) {\n    return Option.some(builder);\n  }\n  return Option.none();\n}), stm.collect(option => Option.isSome(option) ? Option.some(option.value) : Option.none())));\n/** @internal */\nexport const takeSomeSTM = /*#__PURE__*/dual(2, (self, pf) => pipe(findAllSTM(self, (key, value) => core.map(pf(key, value), a => [key, a])), core.map(chunk => RA.isNonEmptyArray(chunk) ? Option.some(chunk) : Option.none()), stm.collect(option => Option.isSome(option) ? Option.some(option.value) : Option.none()), core.flatMap(entries => stm.as(removeAll(self, entries.map(entry => entry[0])), RA.map(entries, entry => entry[1])))));\nconst toReadonlyArray = self => core.effect(journal => {\n  const buckets = tRef.unsafeGet(self.tBuckets, journal);\n  const capacity = buckets.chunk.length;\n  const builder = [];\n  let index = 0;\n  while (index < capacity) {\n    const bucket = buckets.chunk[index];\n    for (const entry of tRef.unsafeGet(bucket, journal)) {\n      builder.push(entry);\n    }\n    index = index + 1;\n  }\n  return builder;\n});\n/** @internal */\nexport const toChunk = self => reduce(self, Chunk.empty(), (acc, value, key) => Chunk.append(acc, [key, value]));\n/** @internal */\nexport const toHashMap = self => reduce(self, HashMap.empty(), (acc, value, key) => pipe(acc, HashMap.set(key, value)));\n/** @internal */\nexport const toArray = self => reduce(self, [], (acc, value, key) => {\n  acc.unshift([key, value]);\n  return acc;\n});\n/** @internal */\nexport const toMap = self => reduce(self, new Map(), (acc, value, key) => acc.set(key, value));\n/** @internal */\nexport const transform = /*#__PURE__*/dual(2, (self, f) => core.effect(journal => {\n  const buckets = pipe(self.tBuckets, tRef.unsafeGet(journal));\n  const capacity = buckets.chunk.length;\n  const newBuckets = Array.from({\n    length: capacity\n  }, () => Chunk.empty());\n  let newSize = 0;\n  let index = 0;\n  while (index < capacity) {\n    const bucket = buckets.chunk[index];\n    const pairs = tRef.unsafeGet(bucket, journal);\n    const iterator = pairs[Symbol.iterator]();\n    let next;\n    while ((next = iterator.next()) && !next.done) {\n      const newPair = f(next.value[0], next.value[1]);\n      const index = indexOf(newPair[0], capacity);\n      const newBucket = newBuckets[index];\n      if (!Chunk.some(newBucket, entry => Equal.equals(entry[0], newPair[0]))) {\n        newBuckets[index] = Chunk.prepend(newBucket, newPair);\n        newSize = newSize + 1;\n      }\n    }\n    index = index + 1;\n  }\n  index = 0;\n  while (index < capacity) {\n    tRef.unsafeSet(buckets.chunk[index], newBuckets[index], journal);\n    index = index + 1;\n  }\n  tRef.unsafeSet(self.tSize, newSize, journal);\n}));\n/** @internal */\nexport const transformSTM = /*#__PURE__*/dual(2, (self, f) => pipe(core.flatMap(toReadonlyArray(self), stm.forEach(entry => f(entry[0], entry[1]))), core.flatMap(newData => core.effect(journal => {\n  const buckets = tRef.unsafeGet(self.tBuckets, journal);\n  const capacity = buckets.chunk.length;\n  const newBuckets = Array.from({\n    length: capacity\n  }, () => Chunk.empty());\n  const iterator = newData[Symbol.iterator]();\n  let newSize = 0;\n  let next;\n  while ((next = iterator.next()) && !next.done) {\n    const index = indexOf(next.value[0], capacity);\n    const newBucket = newBuckets[index];\n    if (!Chunk.some(newBucket, entry => Equal.equals(entry[0])(next.value[0]))) {\n      newBuckets[index] = Chunk.prepend(newBucket, next.value);\n      newSize = newSize + 1;\n    }\n  }\n  let index = 0;\n  while (index < capacity) {\n    tRef.unsafeSet(buckets.chunk[index], newBuckets[index], journal);\n    index = index + 1;\n  }\n  tRef.unsafeSet(self.tSize, newSize, journal);\n}))));\n/** @internal */\nexport const transformValues = /*#__PURE__*/dual(2, (self, f) => transform(self, (key, value) => [key, f(value)]));\n/** @internal */\nexport const transformValuesSTM = /*#__PURE__*/dual(2, (self, f) => transformSTM(self, (key, value) => core.map(f(value), value => [key, value])));\n/** @internal */\nexport const updateWith = /*#__PURE__*/dual(3, (self, key, f) => core.flatMap(get(self, key), option => Option.match(f(option), {\n  onNone: () => stm.as(remove(self, key), Option.none()),\n  onSome: value => stm.as(set(self, key, value), Option.some(value))\n})));\n/** @internal */\nexport const values = self => core.map(toReadonlyArray(self), RA.map(entry => entry[1]));\n//# sourceMappingURL=tMap.js.map",
      "start": 1768772628586,
      "end": 1768772628586
    },
    {
      "name": "sentry-vite-component-name-annotate-plugin",
      "start": 1768772628586,
      "end": 1768772628588,
      "order": "pre"
    },
    {
      "name": "comlink",
      "start": 1768772628620,
      "end": 1768772628621,
      "order": "normal"
    },
    {
      "name": "sentry-vite-bundle-size-optimizations-plugin",
      "start": 1768772628648,
      "end": 1768772628651,
      "order": "normal"
    },
    {
      "name": "vite-plugin-csp-guard",
      "start": 1768772628705,
      "end": 1768772628706,
      "order": "post-post"
    }
  ]
}
