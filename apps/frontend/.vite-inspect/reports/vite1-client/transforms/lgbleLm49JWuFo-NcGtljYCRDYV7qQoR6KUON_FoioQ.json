{
  "resolvedId": "/home/wombocombo/github/wrk/gdg-fsc-website/node_modules/effect/dist/esm/Stream.js",
  "transforms": [
    {
      "name": "__load__",
      "result": "import * as groupBy_ from \"./internal/groupBy.js\";\nimport * as internal from \"./internal/stream.js\";\n/**\n * @since 2.0.0\n * @category symbols\n */\nexport const StreamTypeId = internal.StreamTypeId;\n/**\n * The default chunk size used by the various combinators and constructors of\n * `Stream`.\n *\n * @since 2.0.0\n * @category constants\n */\nexport const DefaultChunkSize = internal.DefaultChunkSize;\n/**\n * Collects each underlying Chunk of the stream into a new chunk, and emits it\n * on each pull.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const accumulate = internal.accumulate;\n/**\n * Re-chunks the elements of the stream by accumulating each underlying chunk.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const accumulateChunks = internal.accumulateChunks;\n/**\n * Creates a stream from a single value that will get cleaned up after the\n * stream is consumed.\n *\n * @example\n * ```ts\n * import { Console, Effect, Stream } from \"effect\"\n *\n * // Simulating File operations\n * const open = (filename: string) =>\n *   Effect.gen(function*() {\n *     yield* Console.log(`Opening ${filename}`)\n *     return {\n *       getLines: Effect.succeed([\"Line 1\", \"Line 2\", \"Line 3\"]),\n *       close: Console.log(`Closing ${filename}`)\n *     }\n *   })\n *\n * const stream = Stream.acquireRelease(\n *   open(\"file.txt\"),\n *   (file) => file.close\n * ).pipe(Stream.flatMap((file) => file.getLines))\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // Opening file.txt\n * // Closing file.txt\n * // { _id: 'Chunk', values: [ [ 'Line 1', 'Line 2', 'Line 3' ] ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const acquireRelease = internal.acquireRelease;\n/**\n * Aggregates elements of this stream using the provided sink for as long as\n * the downstream operators on the stream are busy.\n *\n * This operator divides the stream into two asynchronous \"islands\". Operators\n * upstream of this operator run on one fiber, while downstream operators run\n * on another. Whenever the downstream fiber is busy processing elements, the\n * upstream fiber will feed elements into the sink until it signals\n * completion.\n *\n * Any sink can be used here, but see `Sink.foldWeightedEffect` and\n * `Sink.foldUntilEffect` for sinks that cover the common usecases.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const aggregate = internal.aggregate;\n/**\n * Like {@link aggregateWithinEither}, but only returns the `Right` results.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const aggregateWithin = internal.aggregateWithin;\n/**\n * Aggregates elements using the provided sink until it completes, or until\n * the delay signalled by the schedule has passed.\n *\n * This operator divides the stream into two asynchronous islands. Operators\n * upstream of this operator run on one fiber, while downstream operators run\n * on another. Elements will be aggregated by the sink until the downstream\n * fiber pulls the aggregated value, or until the schedule's delay has passed.\n *\n * Aggregated elements will be fed into the schedule to determine the delays\n * between pulls.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const aggregateWithinEither = internal.aggregateWithinEither;\n/**\n * Maps the success values of this stream to the specified constant value.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.range(1, 5).pipe(Stream.as(null))\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ null, null, null, null, null ] }\n * ```\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const as = internal.as;\nconst _async = internal._async;\nexport {\n/**\n * Creates a stream from an asynchronous callback that can be called multiple\n * times. The optionality of the error type `E` in `Emit` can be used to\n * signal the end of the stream by setting it to `None`.\n *\n * The registration function can optionally return an `Effect`, which will be\n * executed if the `Fiber` executing this Effect is interrupted.\n *\n * @example\n * ```ts\n * import type { StreamEmit } from \"effect\"\n * import { Chunk, Effect, Option, Stream } from \"effect\"\n *\n * const events = [1, 2, 3, 4]\n *\n * const stream = Stream.async(\n *   (emit: StreamEmit.Emit<never, never, number, void>) => {\n *     events.forEach((n) => {\n *       setTimeout(() => {\n *         if (n === 3) {\n *           emit(Effect.fail(Option.none())) // Terminate the stream\n *         } else {\n *           emit(Effect.succeed(Chunk.of(n))) // Add the current item to the stream\n *         }\n *       }, 100 * n)\n *     })\n *   }\n * )\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2 ] }\n *\n * ```\n * @since 2.0.0\n * @category constructors\n */\n_async as async };\n/**\n * Creates a stream from an asynchronous callback that can be called multiple\n * times The registration of the callback itself returns an effect. The\n * optionality of the error type `E` can be used to signal the end of the\n * stream, by setting it to `None`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const asyncEffect = internal.asyncEffect;\n/**\n * Creates a stream from an external push-based resource.\n *\n * You can use the `emit` helper to emit values to the stream. The `emit` helper\n * returns a boolean indicating whether the value was emitted or not.\n *\n * You can also use the `emit` helper to signal the end of the stream by\n * using apis such as `emit.end` or `emit.fail`.\n *\n * By default it uses an \"unbounded\" buffer size.\n * You can customize the buffer size and strategy by passing an object as the\n * second argument with the `bufferSize` and `strategy` fields.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * Stream.asyncPush<string>((emit) =>\n *   Effect.acquireRelease(\n *     Effect.gen(function*() {\n *       yield* Effect.log(\"subscribing\")\n *       return setInterval(() => emit.single(\"tick\"), 1000)\n *     }),\n *     (handle) =>\n *       Effect.gen(function*() {\n *         yield* Effect.log(\"unsubscribing\")\n *         clearInterval(handle)\n *       })\n *   ), { bufferSize: 16, strategy: \"dropping\" })\n * ```\n *\n * @since 3.6.0\n * @category constructors\n */\nexport const asyncPush = internal.asyncPush;\n/**\n * Creates a stream from an asynchronous callback that can be called multiple\n * times. The registration of the callback itself returns an a scoped\n * resource. The optionality of the error type `E` can be used to signal the\n * end of the stream, by setting it to `None`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const asyncScoped = internal.asyncScoped;\n/**\n * Returns a `Stream` that first collects `n` elements from the input `Stream`,\n * and then creates a new `Stream` using the specified function, and sends all\n * the following elements through that.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const branchAfter = internal.branchAfter;\n/**\n * Fan out the stream, producing a list of streams that have the same elements\n * as this stream. The driver stream will only ever advance the `maximumLag`\n * chunks before the slowest downstream stream.\n *\n * @example\n * ```ts\n * import { Console, Effect, Fiber, Schedule, Stream } from \"effect\"\n *\n * const numbers = Effect.scoped(\n *   Stream.range(1, 20).pipe(\n *     Stream.tap((n) => Console.log(`Emit ${n} element before broadcasting`)),\n *     Stream.broadcast(2, 5),\n *     Stream.flatMap(([first, second]) =>\n *       Effect.gen(function*() {\n *         const fiber1 = yield* Stream.runFold(first, 0, (acc, e) => Math.max(acc, e)).pipe(\n *           Effect.andThen((max) => Console.log(`Maximum: ${max}`)),\n *           Effect.fork\n *         )\n *         const fiber2 = yield* second.pipe(\n *           Stream.schedule(Schedule.spaced(\"1 second\")),\n *           Stream.runForEach((n) => Console.log(`Logging to the Console: ${n}`)),\n *           Effect.fork\n *         )\n *         yield* Fiber.join(fiber1).pipe(\n *           Effect.zip(Fiber.join(fiber2), { concurrent: true })\n *         )\n *       })\n *     ),\n *     Stream.runCollect\n *   )\n * )\n *\n * Effect.runPromise(numbers).then(console.log)\n * // Emit 1 element before broadcasting\n * // Emit 2 element before broadcasting\n * // Emit 3 element before broadcasting\n * // Emit 4 element before broadcasting\n * // Emit 5 element before broadcasting\n * // Emit 6 element before broadcasting\n * // Emit 7 element before broadcasting\n * // Emit 8 element before broadcasting\n * // Emit 9 element before broadcasting\n * // Emit 10 element before broadcasting\n * // Emit 11 element before broadcasting\n * // Logging to the Console: 1\n * // Logging to the Console: 2\n * // Logging to the Console: 3\n * // Logging to the Console: 4\n * // Logging to the Console: 5\n * // Emit 12 element before broadcasting\n * // Emit 13 element before broadcasting\n * // Emit 14 element before broadcasting\n * // Emit 15 element before broadcasting\n * // Emit 16 element before broadcasting\n * // Logging to the Console: 6\n * // Logging to the Console: 7\n * // Logging to the Console: 8\n * // Logging to the Console: 9\n * // Logging to the Console: 10\n * // Emit 17 element before broadcasting\n * // Emit 18 element before broadcasting\n * // Emit 19 element before broadcasting\n * // Emit 20 element before broadcasting\n * // Logging to the Console: 11\n * // Logging to the Console: 12\n * // Logging to the Console: 13\n * // Logging to the Console: 14\n * // Logging to the Console: 15\n * // Maximum: 20\n * // Logging to the Console: 16\n * // Logging to the Console: 17\n * // Logging to the Console: 18\n * // Logging to the Console: 19\n * // Logging to the Console: 20\n * // { _id: 'Chunk', values: [ undefined ] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const broadcast = internal.broadcast;\n/**\n * Returns a new Stream that multicasts the original Stream, subscribing to it as soon as the first consumer subscribes.\n * As long as there is at least one consumer, the upstream will continue running and emitting data.\n * When all consumers have exited, the upstream will be finalized.\n *\n * @since 3.8.0\n * @category utils\n */\nexport const share = internal.share;\n/**\n * Fan out the stream, producing a dynamic number of streams that have the\n * same elements as this stream. The driver stream will only ever advance the\n * `maximumLag` chunks before the slowest downstream stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const broadcastDynamic = internal.broadcastDynamic;\n/**\n * Converts the stream to a scoped list of queues. Every value will be\n * replicated to every queue with the slowest queue being allowed to buffer\n * `maximumLag` chunks before the driver is back pressured.\n *\n * Queues can unsubscribe from upstream by shutting down.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const broadcastedQueues = internal.broadcastedQueues;\n/**\n * Converts the stream to a scoped dynamic amount of queues. Every chunk will\n * be replicated to every queue with the slowest queue being allowed to buffer\n * `maximumLag` chunks before the driver is back pressured.\n *\n * Queues can unsubscribe from upstream by shutting down.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const broadcastedQueuesDynamic = internal.broadcastedQueuesDynamic;\n/**\n * Allows a faster producer to progress independently of a slower consumer by\n * buffering up to `capacity` elements in a queue.\n *\n * Note: This combinator destroys the chunking structure. It's recommended to\n *       use rechunk afterwards. Additionally, prefer capacities that are powers\n *       of 2 for better performance.\n *\n * @example\n * ```ts\n * import { Console, Effect, Schedule, Stream } from \"effect\"\n *\n * const stream = Stream.range(1, 10).pipe(\n *   Stream.tap((n) => Console.log(`before buffering: ${n}`)),\n *   Stream.buffer({ capacity: 4 }),\n *   Stream.tap((n) => Console.log(`after buffering: ${n}`)),\n *   Stream.schedule(Schedule.spaced(\"5 seconds\"))\n * )\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // before buffering: 1\n * // before buffering: 2\n * // before buffering: 3\n * // before buffering: 4\n * // before buffering: 5\n * // before buffering: 6\n * // after buffering: 1\n * // after buffering: 2\n * // before buffering: 7\n * // after buffering: 3\n * // before buffering: 8\n * // after buffering: 4\n * // before buffering: 9\n * // after buffering: 5\n * // before buffering: 10\n * // ...\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const buffer = internal.buffer;\n/**\n * Allows a faster producer to progress independently of a slower consumer by\n * buffering up to `capacity` chunks in a queue.\n *\n * @note Prefer capacities that are powers of 2 for better performance.\n * @since 2.0.0\n * @category utils\n */\nexport const bufferChunks = internal.bufferChunks;\n/**\n * Switches over to the stream produced by the provided function in case this\n * one fails with a typed error.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchAll = internal.catchAll;\n/**\n * Switches over to the stream produced by the provided function in case this\n * one fails. Allows recovery from all causes of failure, including\n * interruption if the stream is uninterruptible.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchAllCause = internal.catchAllCause;\n/**\n * Switches over to the stream produced by the provided function in case this\n * one fails with some typed error.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchSome = internal.catchSome;\n/**\n * Switches over to the stream produced by the provided function in case this\n * one fails with an error matching the given `_tag`.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchTag = internal.catchTag;\n/**\n * Switches over to the stream produced by one of the provided functions, in\n * case this one fails with an error matching one of the given `_tag`'s.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchTags = internal.catchTags;\n/**\n * Switches over to the stream produced by the provided function in case this\n * one fails with some errors. Allows recovery from all causes of failure,\n * including interruption if the stream is uninterruptible.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const catchSomeCause = internal.catchSomeCause;\n/**\n * Returns a new stream that only emits elements that are not equal to the\n * previous element emitted, using natural equality to determine whether two\n * elements are equal.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(1, 1, 1, 2, 2, 3, 4).pipe(Stream.changes)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3, 4 ] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const changes = internal.changes;\n/**\n * Returns a new stream that only emits elements that are not equal to the\n * previous element emitted, using the specified function to determine whether\n * two elements are equal.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const changesWith = internal.changesWith;\n/**\n * Returns a new stream that only emits elements that are not equal to the\n * previous element emitted, using the specified effectual function to\n * determine whether two elements are equal.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const changesWithEffect = internal.changesWithEffect;\n/**\n * Exposes the underlying chunks of the stream as a stream of chunks of\n * elements.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const chunks = internal.chunks;\n/**\n * Performs the specified stream transformation with the chunk structure of\n * the stream exposed.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const chunksWith = internal.chunksWith;\n/**\n * Combines the elements from this stream and the specified stream by\n * repeatedly applying the function `f` to extract an element using both sides\n * and conceptually \"offer\" it to the destination stream. `f` can maintain\n * some internal state to control the combining process, with the initial\n * state being specified by `s`.\n *\n * Where possible, prefer `Stream.combineChunks` for a more efficient\n * implementation.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const combine = internal.combine;\n/**\n * Combines the chunks from this stream and the specified stream by repeatedly\n * applying the function `f` to extract a chunk using both sides and\n * conceptually \"offer\" it to the destination stream. `f` can maintain some\n * internal state to control the combining process, with the initial state\n * being specified by `s`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const combineChunks = internal.combineChunks;\n/**\n * Concatenates the specified stream with this stream, resulting in a stream\n * that emits the elements from this stream and then the elements from the\n * specified stream.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const s1 = Stream.make(1, 2, 3)\n * const s2 = Stream.make(4, 5)\n *\n * const stream = Stream.concat(s1, s2)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3, 4, 5 ] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const concat = internal.concat;\n/**\n * Concatenates all of the streams in the chunk to one stream.\n *\n * @example\n * ```ts\n * import { Chunk, Effect, Stream } from \"effect\"\n *\n * const s1 = Stream.make(1, 2, 3)\n * const s2 = Stream.make(4, 5)\n * const s3 = Stream.make(6, 7, 8)\n *\n * const stream = Stream.concatAll(Chunk.make(s1, s2, s3))\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // {\n * //   _id: 'Chunk',\n * //   values: [\n * //     1, 2, 3, 4,\n * //     5, 6, 7, 8\n * //   ]\n * // }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const concatAll = internal.concatAll;\n/**\n * Composes this stream with the specified stream to create a cartesian\n * product of elements. The `right` stream would be run multiple times, for\n * every element in the `left` stream.\n *\n * See also `Stream.zip` for the more common point-wise variant.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const s1 = Stream.make(1, 2, 3)\n * const s2 = Stream.make(\"a\", \"b\")\n *\n * const product = Stream.cross(s1, s2)\n *\n * Effect.runPromise(Stream.runCollect(product)).then(console.log)\n * // {\n * //   _id: \"Chunk\",\n * //   values: [\n * //     [ 1, \"a\" ], [ 1, \"b\" ], [ 2, \"a\" ], [ 2, \"b\" ], [ 3, \"a\" ], [ 3, \"b\" ]\n * //   ]\n * // }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const cross = internal.cross;\n/**\n * Composes this stream with the specified stream to create a cartesian\n * product of elements, but keeps only elements from `left` stream. The `right`\n * stream would be run multiple times, for every element in the `left` stream.\n *\n * See also `Stream.zipLeft` for the more common point-wise variant.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const crossLeft = internal.crossLeft;\n/**\n * Composes this stream with the specified stream to create a cartesian\n * product of elements, but keeps only elements from the `right` stream. The\n * `left` stream would be run multiple times, for every element in the `right`\n * stream.\n *\n * See also `Stream.zipRight` for the more common point-wise variant.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const crossRight = internal.crossRight;\n/**\n * Composes this stream with the specified stream to create a cartesian\n * product of elements with a specified function. The `right` stream would be\n * run multiple times, for every element in the `left` stream.\n *\n * See also `Stream.zipWith` for the more common point-wise variant.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const crossWith = internal.crossWith;\n/**\n * Delays the emission of values by holding new values for a set duration. If\n * no new values arrive during that time the value is emitted, however if a\n * new value is received during the holding period the previous value is\n * discarded and the process is repeated with the new value.\n *\n * This operator is useful if you have a stream of \"bursty\" events which\n * eventually settle down and you only need the final event of the burst. For\n * example, a search engine may only want to initiate a search after a user\n * has paused typing so as to not prematurely recommend results.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * let last = Date.now()\n * const log = (message: string) =>\n *   Effect.sync(() => {\n *     const end = Date.now()\n *     console.log(`${message} after ${end - last}ms`)\n *     last = end\n *   })\n *\n * const stream = Stream.make(1, 2, 3).pipe(\n *   Stream.concat(\n *     Stream.fromEffect(Effect.sleep(\"200 millis\").pipe(Effect.as(4))) // Emit 4 after 200 ms\n *   ),\n *   Stream.concat(Stream.make(5, 6)), // Continue with more rapid values\n *   Stream.concat(\n *     Stream.fromEffect(Effect.sleep(\"150 millis\").pipe(Effect.as(7))) // Emit 7 after 150 ms\n *   ),\n *   Stream.concat(Stream.make(8)),\n *   Stream.tap((n) => log(`Received ${n}`)),\n *   Stream.debounce(\"100 millis\"), // Only emit values after a pause of at least 100 milliseconds,\n *   Stream.tap((n) => log(`> Emitted ${n}`))\n * )\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // Received 1 after 5ms\n * // Received 2 after 2ms\n * // Received 3 after 0ms\n * // > Emitted 3 after 104ms\n * // Received 4 after 99ms\n * // Received 5 after 1ms\n * // Received 6 after 0ms\n * // > Emitted 6 after 101ms\n * // Received 7 after 50ms\n * // Received 8 after 1ms\n * // > Emitted 8 after 101ms\n * // { _id: 'Chunk', values: [ 3, 6, 8 ] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const debounce = internal.debounce;\n/**\n * The stream that dies with the specified defect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const die = internal.die;\n/**\n * The stream that dies with the specified lazily evaluated defect.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dieSync = internal.dieSync;\n/**\n * The stream that dies with an exception described by `message`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const dieMessage = internal.dieMessage;\n/**\n * More powerful version of `Stream.broadcast`. Allows to provide a function\n * that determines what queues should receive which elements. The decide\n * function will receive the indices of the queues in the resulting list.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const distributedWith = internal.distributedWith;\n/**\n * More powerful version of `Stream.distributedWith`. This returns a function\n * that will produce new queues and corresponding indices. You can also\n * provide a function that will be executed after the final events are\n * enqueued in all queues. Shutdown of the queues is handled by the driver.\n * Downstream users can also shutdown queues manually. In this case the driver\n * will continue but no longer backpressure on them.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const distributedWithDynamic = internal.distributedWithDynamic;\n/**\n * Converts this stream to a stream that executes its effects but emits no\n * elements. Useful for sequencing effects using streams:\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * // We create a stream and immediately drain it.\n * const stream = Stream.range(1, 6).pipe(Stream.drain)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const drain = internal.drain;\n/**\n * Drains the provided stream in the background for as long as this stream is\n * running. If this stream ends before `other`, `other` will be interrupted.\n * If `other` fails, this stream will fail with that error.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const drainFork = internal.drainFork;\n/**\n * Drops the specified number of elements from this stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const drop = internal.drop;\n/**\n * Drops the last specified number of elements from this stream.\n *\n * @note This combinator keeps `n` elements in memory. Be careful with big\n *       numbers.\n * @since 2.0.0\n * @category utils\n */\nexport const dropRight = internal.dropRight;\n/**\n * Drops all elements of the stream until the specified predicate evaluates to\n * `true`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const dropUntil = internal.dropUntil;\n/**\n * Drops all elements of the stream until the specified effectful predicate\n * evaluates to `true`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const dropUntilEffect = internal.dropUntilEffect;\n/**\n * Drops all elements of the stream for as long as the specified predicate\n * evaluates to `true`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const dropWhile = internal.dropWhile;\n/**\n * Drops all elements of the stream for as long as the specified predicate\n * produces an effect that evalutates to `true`\n *\n * @since 2.0.0\n * @category utils\n */\nexport const dropWhileEffect = internal.dropWhileEffect;\n/**\n * Returns a stream whose failures and successes have been lifted into an\n * `Either`. The resulting stream cannot fail, because the failures have been\n * exposed as part of the `Either` success case.\n *\n * @note The stream will end as soon as the first error occurs.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const either = internal.either;\n/**\n * The empty stream.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.empty\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const empty = internal.empty;\n/**\n * Executes the provided finalizer after this stream's finalizers run.\n *\n * @example\n * ```ts\n * import { Console, Effect, Stream } from \"effect\"\n *\n * const program = Stream.fromEffect(Console.log(\"Application Logic.\")).pipe(\n *   Stream.concat(Stream.finalizer(Console.log(\"Finalizing the stream\"))),\n *   Stream.ensuring(\n *     Console.log(\"Doing some other works after stream's finalization\")\n *   )\n * )\n *\n * Effect.runPromise(Stream.runCollect(program)).then(console.log)\n * // Application Logic.\n * // Finalizing the stream\n * // Doing some other works after stream's finalization\n * // { _id: 'Chunk', values: [ undefined, undefined ] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const ensuring = internal.ensuring;\n/**\n * Executes the provided finalizer after this stream's finalizers run.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const ensuringWith = internal.ensuringWith;\n/**\n * Accesses the whole context of the stream.\n *\n * @since 2.0.0\n * @category context\n */\nexport const context = internal.context;\n/**\n * Accesses the context of the stream.\n *\n * @since 2.0.0\n * @category context\n */\nexport const contextWith = internal.contextWith;\n/**\n * Accesses the context of the stream in the context of an effect.\n *\n * @since 2.0.0\n * @category context\n */\nexport const contextWithEffect = internal.contextWithEffect;\n/**\n * Accesses the context of the stream in the context of a stream.\n *\n * @since 2.0.0\n * @category context\n */\nexport const contextWithStream = internal.contextWithStream;\n/**\n * Creates a stream that executes the specified effect but emits no elements.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const execute = internal.execute;\n/**\n * Terminates with the specified error.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.fail(\"Uh oh!\")\n *\n * Effect.runPromiseExit(Stream.runCollect(stream)).then(console.log)\n * // {\n * //   _id: 'Exit',\n * //   _tag: 'Failure',\n * //   cause: { _id: 'Cause', _tag: 'Fail', failure: 'Uh oh!' }\n * // }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fail = internal.fail;\n/**\n * Terminates with the specified lazily evaluated error.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failSync = internal.failSync;\n/**\n * The stream that always fails with the specified `Cause`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failCause = internal.failCause;\n/**\n * The stream that always fails with the specified lazily evaluated `Cause`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const failCauseSync = internal.failCauseSync;\n/**\n * Filters the elements emitted by this stream using the provided function.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.range(1, 11).pipe(Stream.filter((n) => n % 2 === 0))\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 2, 4, 6, 8, 10 ] }\n * ```\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const filter = internal.filter;\n/**\n * Effectfully filters the elements emitted by this stream.\n *\n * @since 2.0.0\n * @category filtering\n */\nexport const filterEffect = internal.filterEffect;\n/**\n * Performs a filter and map in a single step.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const filterMap = internal.filterMap;\n/**\n * Performs an effectful filter and map in a single step.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const filterMapEffect = internal.filterMapEffect;\n/**\n * Transforms all elements of the stream for as long as the specified partial\n * function is defined.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const filterMapWhile = internal.filterMapWhile;\n/**\n * Effectfully transforms all elements of the stream for as long as the\n * specified partial function is defined.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const filterMapWhileEffect = internal.filterMapWhileEffect;\n/**\n * Creates a one-element stream that never fails and executes the finalizer\n * when it ends.\n *\n * @example\n * ```ts\n * import { Console, Effect, Stream } from \"effect\"\n *\n * const application = Stream.fromEffect(Console.log(\"Application Logic.\"))\n *\n * const deleteDir = (dir: string) => Console.log(`Deleting dir: ${dir}`)\n *\n * const program = application.pipe(\n *   Stream.concat(\n *     Stream.finalizer(\n *       deleteDir(\"tmp\").pipe(\n *         Effect.andThen(Console.log(\"Temporary directory was deleted.\"))\n *       )\n *     )\n *   )\n * )\n *\n * Effect.runPromise(Stream.runCollect(program)).then(console.log)\n * // Application Logic.\n * // Deleting dir: tmp\n * // Temporary directory was deleted.\n * // { _id: 'Chunk', values: [ undefined, undefined ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const finalizer = internal.finalizer;\n/**\n * Finds the first element emitted by this stream that satisfies the provided\n * predicate.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const find = internal.find;\n/**\n * Finds the first element emitted by this stream that satisfies the provided\n * effectful predicate.\n *\n * @since 2.0.0\n * @category elements\n */\nexport const findEffect = internal.findEffect;\n/**\n * Returns a stream made of the concatenation in strict order of all the\n * streams produced by passing each element of this stream to `f0`\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatMap = internal.flatMap;\n/**\n * Flattens this stream-of-streams into a stream made of the concatenation in\n * strict order of all the streams.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flatten = internal.flatten;\n/**\n * Submerges the chunks carried by this stream into the stream's structure,\n * while still preserving them.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flattenChunks = internal.flattenChunks;\n/**\n * Flattens `Effect` values into the stream's structure, preserving all\n * information about the effect.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flattenEffect = internal.flattenEffect;\n/**\n * Unwraps `Exit` values that also signify end-of-stream by failing with `None`.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flattenExitOption = internal.flattenExitOption;\n/**\n * Submerges the iterables carried by this stream into the stream's structure,\n * while still preserving them.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flattenIterables = internal.flattenIterables;\n/**\n * Unwraps `Exit` values and flatten chunks that also signify end-of-stream\n * by failing with `None`.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const flattenTake = internal.flattenTake;\n/**\n * Repeats this stream forever.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const forever = internal.forever;\n/**\n * Creates a stream from an `AsyncIterable`.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const myAsyncIterable = async function*() {\n *   yield 1\n *   yield 2\n * }\n *\n * const stream = Stream.fromAsyncIterable(\n *   myAsyncIterable(),\n *   (e) => new Error(String(e)) // Error Handling\n * )\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromAsyncIterable = internal.fromAsyncIterable;\n/**\n * Creates a stream from a `Channel`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromChannel = internal.fromChannel;\n/**\n * Creates a channel from a `Stream`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const toChannel = internal.toChannel;\n/**\n * Creates a stream from a `Chunk` of values.\n *\n * @example\n * ```ts\n * import { Chunk, Effect, Stream } from \"effect\"\n *\n * // Creating a stream with values from a single Chunk\n * const stream = Stream.fromChunk(Chunk.make(1, 2, 3))\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromChunk = internal.fromChunk;\n/**\n * Creates a stream from a subscription to a `PubSub`.\n *\n * **Options**\n *\n * - `shutdown`: If `true`, the `PubSub` will be shutdown after the stream is evaluated (defaults to `false`)\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromChunkPubSub = internal.fromChunkPubSub;\n/**\n * Creates a stream from a `Queue` of values.\n *\n * **Options**\n *\n * - `shutdown`: If `true`, the queue will be shutdown after the stream is evaluated (defaults to `false`)\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromChunkQueue = internal.fromChunkQueue;\n/**\n * Creates a stream from an arbitrary number of chunks.\n *\n * @example\n * ```ts\n * import { Chunk, Effect, Stream } from \"effect\"\n *\n * // Creating a stream with values from multiple Chunks\n * const stream = Stream.fromChunks(Chunk.make(1, 2, 3), Chunk.make(4, 5, 6))\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3, 4, 5, 6 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromChunks = internal.fromChunks;\n/**\n * Either emits the success value of this effect or terminates the stream\n * with the failure value of this effect.\n *\n * @example\n * ```ts\n * import { Effect, Random, Stream } from \"effect\"\n *\n * const stream = Stream.fromEffect(Random.nextInt)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // Example Output: { _id: 'Chunk', values: [ 922694024 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromEffect = internal.fromEffect;\n/**\n * Creates a stream from an effect producing a value of type `A` or an empty\n * `Stream`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromEffectOption = internal.fromEffectOption;\n/**\n * Creates a stream from a subscription to a `PubSub`.\n *\n * **Options**\n *\n * - `shutdown`: If `true`, the `PubSub` will be shutdown after the stream is evaluated (defaults to `false`)\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromPubSub = internal.fromPubSub;\n/**\n * Creates a stream from a subscription to a `TPubSub`.\n *\n * @since 3.10.0\n * @category constructors\n */\nexport const fromTPubSub = internal.fromTPubSub;\n/**\n * Creates a new `Stream` from an iterable collection of values.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const numbers = [1, 2, 3]\n *\n * const stream = Stream.fromIterable(numbers)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromIterable = internal.fromIterable;\n/**\n * Creates a stream from an effect producing a value of type `Iterable<A>`.\n *\n * @example\n * ```ts\n * import { Context, Effect, Stream } from \"effect\"\n *\n * class Database extends Context.Tag(\"Database\")<\n *   Database,\n *   { readonly getUsers: Effect.Effect<Array<string>> }\n * >() {}\n *\n * const getUsers = Database.pipe(Effect.andThen((_) => _.getUsers))\n *\n * const stream = Stream.fromIterableEffect(getUsers)\n *\n * Effect.runPromise(\n *   Stream.runCollect(stream.pipe(Stream.provideService(Database, { getUsers: Effect.succeed([\"user1\", \"user2\"]) })))\n * ).then(console.log)\n * // { _id: 'Chunk', values: [ 'user1', 'user2' ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromIterableEffect = internal.fromIterableEffect;\n/**\n * Creates a stream from an iterator\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromIteratorSucceed = internal.fromIteratorSucceed;\n/**\n * Creates a stream from an effect that pulls elements from another stream.\n *\n * See `Stream.toPull` for reference.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromPull = internal.fromPull;\n/**\n * Creates a stream from a queue of values\n *\n * **Options**\n *\n * - `maxChunkSize`: The maximum number of queued elements to put in one chunk in the stream\n * - `shutdown`: If `true`, the queue will be shutdown after the stream is evaluated (defaults to `false`)\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromQueue = internal.fromQueue;\n/**\n * Creates a stream from a TQueue of values\n *\n * @since 3.10.0\n * @category constructors\n */\nexport const fromTQueue = internal.fromTQueue;\n/**\n * Creates a stream from a `ReadableStream`.\n *\n * See https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromReadableStream = internal.fromReadableStream;\n/**\n * Creates a stream from a `ReadableStreamBYOBReader`.\n *\n * See https://developer.mozilla.org/en-US/docs/Web/API/ReadableStreamBYOBReader.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromReadableStreamByob = internal.fromReadableStreamByob;\n/**\n * Creates a stream from a `Schedule` that does not require any further\n * input. The stream will emit an element for each value output from the\n * schedule, continuing for as long as the schedule continues.\n *\n * @example\n * ```ts\n * import { Effect, Schedule, Stream } from \"effect\"\n *\n * // Emits values every 1 second for a total of 5 emissions\n * const schedule = Schedule.spaced(\"1 second\").pipe(\n *   Schedule.compose(Schedule.recurs(5))\n * )\n *\n * const stream = Stream.fromSchedule(schedule)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 0, 1, 2, 3, 4 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const fromSchedule = internal.fromSchedule;\n/**\n * Creates a pipeline that groups on adjacent keys, calculated by the\n * specified function.\n *\n * @since 2.0.0\n * @category grouping\n */\nexport const groupAdjacentBy = internal.groupAdjacentBy;\n/**\n * More powerful version of `Stream.groupByKey`.\n *\n * @example\n * ```ts\n * import { Chunk, Effect, GroupBy, Stream } from \"effect\"\n *\n * const groupByKeyResult = Stream.fromIterable([\n *   \"Mary\",\n *   \"James\",\n *   \"Robert\",\n *   \"Patricia\",\n *   \"John\",\n *   \"Jennifer\",\n *   \"Rebecca\",\n *   \"Peter\"\n * ]).pipe(\n *   Stream.groupBy((name) => Effect.succeed([name.substring(0, 1), name]))\n * )\n *\n * const stream = GroupBy.evaluate(groupByKeyResult, (key, stream) =>\n *   Stream.fromEffect(\n *     Stream.runCollect(stream).pipe(\n *       Effect.andThen((chunk) => [key, Chunk.size(chunk)] as const)\n *     )\n *   ))\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // {\n * //   _id: 'Chunk',\n * //   values: [ [ 'M', 1 ], [ 'J', 3 ], [ 'R', 2 ], [ 'P', 2 ] ]\n * // }\n * ```\n *\n * @since 2.0.0\n * @category grouping\n */\nexport const groupBy = groupBy_.groupBy;\n/**\n * Partition a stream using a function and process each stream individually.\n * This returns a data structure that can be used to further filter down which\n * groups shall be processed.\n *\n * After calling apply on the GroupBy object, the remaining groups will be\n * processed in parallel and the resulting streams merged in a\n * nondeterministic fashion.\n *\n * Up to `buffer` elements may be buffered in any group stream before the\n * producer is backpressured. Take care to consume from all streams in order\n * to prevent deadlocks.\n *\n * For example, to collect the first 2 words for every starting letter from a\n * stream of words:\n *\n * ```ts\n * import { pipe, GroupBy, Stream } from \"effect\"\n *\n * pipe(\n *   Stream.fromIterable([\"hello\", \"world\", \"hi\", \"holla\"]),\n *   Stream.groupByKey((word) => word[0]),\n *   GroupBy.evaluate((key, stream) =>\n *     pipe(\n *       stream,\n *       Stream.take(2),\n *       Stream.map((words) => [key, words] as const)\n *     )\n *   )\n * )\n * ```\n *\n * @since 2.0.0\n * @category grouping\n */\nexport const groupByKey = groupBy_.groupByKey;\n/**\n * Partitions the stream with specified `chunkSize`.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.range(0, 8).pipe(Stream.grouped(3))\n *\n * Effect.runPromise(Stream.runCollect(stream)).then((chunks) => console.log(\"%o\", chunks))\n * // {\n * //   _id: 'Chunk',\n * //   values: [\n * //     { _id: 'Chunk', values: [ 0, 1, 2, [length]: 3 ] },\n * //     { _id: 'Chunk', values: [ 3, 4, 5, [length]: 3 ] },\n * //     { _id: 'Chunk', values: [ 6, 7, 8, [length]: 3 ] },\n * //     [length]: 3\n * //   ]\n * // }\n * ```\n *\n * @since 2.0.0\n * @category grouping\n */\nexport const grouped = internal.grouped;\n/**\n * Partitions the stream with the specified `chunkSize` or until the specified\n * `duration` has passed, whichever is satisfied first.\n *\n * @example\n * ```ts\n * import { Chunk, Effect, Schedule, Stream } from \"effect\"\n *\n * const stream = Stream.range(0, 9).pipe(\n *   Stream.repeat(Schedule.spaced(\"1 second\")),\n *   Stream.groupedWithin(18, \"1.5 seconds\"),\n *   Stream.take(3)\n * )\n *\n * Effect.runPromise(Stream.runCollect(stream)).then((chunks) => console.log(Chunk.toArray(chunks)))\n * // [\n * //   {\n * //     _id: 'Chunk',\n * //     values: [\n * //       0, 1, 2, 3, 4, 5, 6,\n * //       7, 8, 9, 0, 1, 2, 3,\n * //       4, 5, 6, 7\n * //     ]\n * //   },\n * //   {\n * //     _id: 'Chunk',\n * //     values: [\n * //       8, 9, 0, 1, 2,\n * //       3, 4, 5, 6, 7,\n * //       8, 9\n * //     ]\n * //   },\n * //   {\n * //     _id: 'Chunk',\n * //     values: [\n * //       0, 1, 2, 3, 4, 5, 6,\n * //       7, 8, 9, 0, 1, 2, 3,\n * //       4, 5, 6, 7\n * //     ]\n * //   }\n * // ]\n * ```\n *\n * @since 2.0.0\n * @category grouping\n */\nexport const groupedWithin = internal.groupedWithin;\n/**\n * Specialized version of haltWhen which halts the evaluation of this stream\n * after the given duration.\n *\n * An element in the process of being pulled will not be interrupted when the\n * given duration completes. See `interruptAfter` for this behavior.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const haltAfter = internal.haltAfter;\n/**\n * Halts the evaluation of this stream when the provided effect completes. The\n * given effect will be forked as part of the returned stream, and its success\n * will be discarded.\n *\n * An element in the process of being pulled will not be interrupted when the\n * effect completes. See `interruptWhen` for this behavior.\n *\n * If the effect completes with a failure, the stream will emit that failure.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const haltWhen = internal.haltWhen;\n/**\n * Halts the evaluation of this stream when the provided promise resolves.\n *\n * If the promise completes with a failure, the stream will emit that failure.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const haltWhenDeferred = internal.haltWhenDeferred;\n/**\n * The identity pipeline, which does not modify streams in any way.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const identity = internal.identityStream;\n/**\n * Interleaves this stream and the specified stream deterministically by\n * alternating pulling values from this stream and the specified stream. When\n * one stream is exhausted all remaining values in the other stream will be\n * pulled.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const s1 = Stream.make(1, 2, 3)\n * const s2 = Stream.make(4, 5, 6)\n *\n * const stream = Stream.interleave(s1, s2)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 4, 2, 5, 3, 6 ] }\n * ```\n * @since 2.0.0\n * @category utils\n */\nexport const interleave = internal.interleave;\n/**\n * Combines this stream and the specified stream deterministically using the\n * stream of boolean values `pull` to control which stream to pull from next.\n * A value of `true` indicates to pull from this stream and a value of `false`\n * indicates to pull from the specified stream. Only consumes as many elements\n * as requested by the `pull` stream. If either this stream or the specified\n * stream are exhausted further requests for values from that stream will be\n * ignored.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const s1 = Stream.make(1, 3, 5, 7, 9)\n * const s2 = Stream.make(2, 4, 6, 8, 10)\n *\n * const booleanStream = Stream.make(true, false, false).pipe(Stream.forever)\n *\n * const stream = Stream.interleaveWith(s1, s2, booleanStream)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // {\n * //   _id: 'Chunk',\n * //   values: [\n * //     1, 2,  4, 3, 6,\n * //     8, 5, 10, 7, 9\n * //   ]\n * // }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const interleaveWith = internal.interleaveWith;\n/**\n * Intersperse stream with provided `element`.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(1, 2, 3, 4, 5).pipe(Stream.intersperse(0))\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // {\n * //   _id: 'Chunk',\n * //   values: [\n * //     1, 0, 2, 0, 3,\n * //     0, 4, 0, 5\n * //   ]\n * // }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const intersperse = internal.intersperse;\n/**\n * Intersperse the specified element, also adding a prefix and a suffix.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(1, 2, 3, 4, 5).pipe(\n *   Stream.intersperseAffixes({\n *     start: \"[\",\n *     middle: \"-\",\n *     end: \"]\"\n *   })\n * )\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // {\n * //   _id: 'Chunk',\n * //   values: [\n * //     '[', 1,   '-', 2,   '-',\n * //     3,   '-', 4,   '-', 5,\n * //     ']'\n * //   ]\n * // }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const intersperseAffixes = internal.intersperseAffixes;\n/**\n * Specialized version of `Stream.interruptWhen` which interrupts the\n * evaluation of this stream after the given `Duration`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const interruptAfter = internal.interruptAfter;\n/**\n * Interrupts the evaluation of this stream when the provided effect\n * completes. The given effect will be forked as part of this stream, and its\n * success will be discarded. This combinator will also interrupt any\n * in-progress element being pulled from upstream.\n *\n * If the effect completes with a failure before the stream completes, the\n * returned stream will emit that failure.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const interruptWhen = internal.interruptWhen;\n/**\n * Interrupts the evaluation of this stream when the provided promise\n * resolves. This combinator will also interrupt any in-progress element being\n * pulled from upstream.\n *\n * If the promise completes with a failure, the stream will emit that failure.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const interruptWhenDeferred = internal.interruptWhenDeferred;\n/**\n * The infinite stream of iterative function application: a, f(a), f(f(a)),\n * f(f(f(a))), ...\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * // An infinite Stream of numbers starting from 1 and incrementing\n * const stream = Stream.iterate(1, (n) => n + 1)\n *\n * Effect.runPromise(Stream.runCollect(stream.pipe(Stream.take(10)))).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const iterate = internal.iterate;\n/**\n * Creates a stream from an sequence of values.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(1, 2, 3)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const make = internal.make;\n/**\n * Transforms the elements of this stream using the supplied function.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(1, 2, 3).pipe(Stream.map((n) => n + 1))\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 2, 3, 4 ] }\n * ```\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const map = internal.map;\n/**\n * Statefully maps over the elements of this stream to produce new elements.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const runningTotal = (stream: Stream.Stream<number>): Stream.Stream<number> =>\n *   stream.pipe(Stream.mapAccum(0, (s, a) => [s + a, s + a]))\n *\n * // input:  0, 1, 2, 3, 4, 5, 6\n * Effect.runPromise(Stream.runCollect(runningTotal(Stream.range(0, 6)))).then(\n *   console.log\n * )\n * // { _id: \"Chunk\", values: [ 0, 1, 3, 6, 10, 15, 21 ] }\n * ```\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapAccum = internal.mapAccum;\n/**\n * Statefully and effectfully maps over the elements of this stream to produce\n * new elements.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapAccumEffect = internal.mapAccumEffect;\n/**\n * Returns a stream whose failure and success channels have been mapped by the\n * specified `onFailure` and `onSuccess` functions.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mapBoth = internal.mapBoth;\n/**\n * Transforms the chunks emitted by this stream.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapChunks = internal.mapChunks;\n/**\n * Effectfully transforms the chunks emitted by this stream.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapChunksEffect = internal.mapChunksEffect;\n/**\n * Maps each element to an iterable, and flattens the iterables into the\n * output of this stream.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const numbers = Stream.make(\"1-2-3\", \"4-5\", \"6\").pipe(\n *   Stream.mapConcat((s) => s.split(\"-\")),\n *   Stream.map((s) => parseInt(s))\n * )\n *\n * Effect.runPromise(Stream.runCollect(numbers)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3, 4, 5, 6 ] }\n * ```\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapConcat = internal.mapConcat;\n/**\n * Maps each element to a chunk, and flattens the chunks into the output of\n * this stream.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapConcatChunk = internal.mapConcatChunk;\n/**\n * Effectfully maps each element to a chunk, and flattens the chunks into the\n * output of this stream.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapConcatChunkEffect = internal.mapConcatChunkEffect;\n/**\n * Effectfully maps each element to an iterable, and flattens the iterables\n * into the output of this stream.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapConcatEffect = internal.mapConcatEffect;\n/**\n * Maps over elements of the stream with the specified effectful function.\n *\n * @example\n * ```ts\n * import { Effect, Random, Stream } from \"effect\"\n *\n * const stream = Stream.make(10, 20, 30).pipe(\n *   Stream.mapEffect((n) => Random.nextIntBetween(0, n))\n * )\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // Example Output: { _id: 'Chunk', values: [ 7, 19, 8 ] }\n * ```\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapEffect = groupBy_.mapEffectOptions;\n/**\n * Transforms the errors emitted by this stream using `f`.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapError = internal.mapError;\n/**\n * Transforms the full causes of failures emitted by this stream.\n *\n * @since 2.0.0\n * @category mapping\n */\nexport const mapErrorCause = internal.mapErrorCause;\n/**\n * Merges this stream and the specified stream together.\n *\n * New produced stream will terminate when both specified stream terminate if\n * no termination strategy is specified.\n *\n * @example\n * ```ts\n * import { Effect, Schedule, Stream } from \"effect\"\n *\n * const s1 = Stream.make(1, 2, 3).pipe(\n *   Stream.schedule(Schedule.spaced(\"100 millis\"))\n * )\n * const s2 = Stream.make(4, 5, 6).pipe(\n *   Stream.schedule(Schedule.spaced(\"200 millis\"))\n * )\n *\n * const stream = Stream.merge(s1, s2)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 4, 2, 3, 5, 6 ] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const merge = internal.merge;\n/**\n * Merges a variable list of streams in a non-deterministic fashion. Up to `n`\n * streams may be consumed in parallel and up to `outputBuffer` chunks may be\n * buffered by this operator.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mergeAll = internal.mergeAll;\n/**\n * Merges a struct of streams into a single stream of tagged values.\n * @category combinators\n * @since 3.8.5\n *\n * @example\n * ```ts\n * import { Stream } from \"effect\"\n * // Stream.Stream<{ _tag: \"a\"; value: number; } | { _tag: \"b\"; value: string; }>\n * const res = Stream.mergeWithTag({\n *    a: Stream.make(0),\n *    b: Stream.make(\"\")\n * }, { concurrency: \"unbounded\" })\n * ```\n */\nexport const mergeWithTag = internal.mergeWithTag;\n/**\n * Merges this stream and the specified stream together to a common element\n * type with the specified mapping functions.\n *\n * New produced stream will terminate when both specified stream terminate if\n * no termination strategy is specified.\n *\n * @example\n * ```ts\n * import { Effect, Schedule, Stream } from \"effect\"\n *\n * const s1 = Stream.make(\"1\", \"2\", \"3\").pipe(\n *   Stream.schedule(Schedule.spaced(\"100 millis\"))\n * )\n * const s2 = Stream.make(4.1, 5.3, 6.2).pipe(\n *   Stream.schedule(Schedule.spaced(\"200 millis\"))\n * )\n *\n * const stream = Stream.mergeWith(s1, s2, {\n *   onSelf: (s) => parseInt(s),\n *   onOther: (n) => Math.floor(n)\n * })\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 4, 2, 3, 5, 6 ] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mergeWith = internal.mergeWith;\n/**\n * Merges this stream and the specified stream together to produce a stream of\n * eithers.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mergeEither = internal.mergeEither;\n/**\n * Merges this stream and the specified stream together, discarding the values\n * from the right stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mergeLeft = internal.mergeLeft;\n/**\n * Merges this stream and the specified stream together, discarding the values\n * from the left stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mergeRight = internal.mergeRight;\n/**\n * Returns a combined string resulting from concatenating each of the values\n * from the stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const mkString = internal.mkString;\n/**\n * The stream that never produces any value or fails with any error.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const never = internal.never;\n/**\n * Adds an effect to be executed at the end of the stream.\n *\n * @example\n * ```ts\n * import { Console, Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(1, 2, 3).pipe(\n *   Stream.map((n) => n * 2),\n *   Stream.tap((n) => Console.log(`after mapping: ${n}`)),\n *   Stream.onEnd(Console.log(\"Stream ended\"))\n * )\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // after mapping: 2\n * // after mapping: 4\n * // after mapping: 6\n * // Stream ended\n * // { _id: 'Chunk', values: [ 2, 4, 6 ] }\n * ```\n *\n * @since 3.6.0\n * @category sequencing\n */\nexport const onEnd = internal.onEnd;\n/**\n * Runs the specified effect if this stream fails, providing the error to the\n * effect if it exists.\n *\n * Note: Unlike `Effect.onError` there is no guarantee that the provided\n * effect will not be interrupted.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const onError = internal.onError;\n/**\n * Runs the specified effect if this stream ends.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const onDone = internal.onDone;\n/**\n * Adds an effect to be executed at the start of the stream.\n *\n * @example\n * ```ts\n * import { Console, Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(1, 2, 3).pipe(\n *   Stream.onStart(Console.log(\"Stream started\")),\n *   Stream.map((n) => n * 2),\n *   Stream.tap((n) => Console.log(`after mapping: ${n}`))\n * )\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // Stream started\n * // after mapping: 2\n * // after mapping: 4\n * // after mapping: 6\n * // { _id: 'Chunk', values: [ 2, 4, 6 ] }\n * ```\n *\n * @since 3.6.0\n * @category sequencing\n */\nexport const onStart = internal.onStart;\n/**\n * Translates any failure into a stream termination, making the stream\n * infallible and all failures unchecked.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orDie = internal.orDie;\n/**\n * Keeps none of the errors, and terminates the stream with them, using the\n * specified function to convert the `E` into a defect.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orDieWith = internal.orDieWith;\n/**\n * Switches to the provided stream in case this one fails with a typed error.\n *\n * See also `Stream.catchAll`.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElse = internal.orElse;\n/**\n * Switches to the provided stream in case this one fails with a typed error.\n *\n * See also `Stream.catchAll`.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElseEither = internal.orElseEither;\n/**\n * Fails with given error in case this one fails with a typed error.\n *\n * See also `Stream.catchAll`.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElseFail = internal.orElseFail;\n/**\n * Produces the specified element if this stream is empty.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElseIfEmpty = internal.orElseIfEmpty;\n/**\n * Produces the specified chunk if this stream is empty.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElseIfEmptyChunk = internal.orElseIfEmptyChunk;\n/**\n * Switches to the provided stream in case this one is empty.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElseIfEmptyStream = internal.orElseIfEmptyStream;\n/**\n * Succeeds with the specified value if this one fails with a typed error.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const orElseSucceed = internal.orElseSucceed;\n/**\n * Like `Stream.unfold`, but allows the emission of values to end one step further\n * than the unfolding of the state. This is useful for embedding paginated\n * APIs, hence the name.\n *\n * @example\n * ```ts\n * import { Effect, Option, Stream } from \"effect\"\n *\n * const stream = Stream.paginate(0, (n) => [\n *   n,\n *   n < 3 ? Option.some(n + 1) : Option.none()\n * ])\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 0, 1, 2, 3 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const paginate = internal.paginate;\n/**\n * Like `Stream.unfoldChunk`, but allows the emission of values to end one step\n * further than the unfolding of the state. This is useful for embedding\n * paginated APIs, hence the name.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const paginateChunk = internal.paginateChunk;\n/**\n * Like `Stream.unfoldChunkEffect`, but allows the emission of values to end one step\n * further than the unfolding of the state. This is useful for embedding\n * paginated APIs, hence the name.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const paginateChunkEffect = internal.paginateChunkEffect;\n/**\n * Like `Stream.unfoldEffect` but allows the emission of values to end one step\n * further than the unfolding of the state. This is useful for embedding\n * paginated APIs, hence the name.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const paginateEffect = internal.paginateEffect;\n/**\n * Splits a stream into two substreams based on a predicate.\n *\n * **Details**\n *\n * The `Stream.partition` function splits a stream into two parts: one for\n * elements that satisfy the predicate (evaluated to `true`) and another for\n * those that do not (evaluated to `false`).\n *\n * The faster stream may advance up to `bufferSize` elements ahead of the slower\n * one.\n *\n * **Example** (Partitioning a Stream into Even and Odd Numbers)\n *\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const partition = Stream.range(1, 9).pipe(\n *   Stream.partition((n) => n % 2 === 0, { bufferSize: 5 })\n * )\n *\n * const program = Effect.scoped(\n *   Effect.gen(function*() {\n *     const [odds, evens] = yield* partition\n *     console.log(yield* Stream.runCollect(odds))\n *     console.log(yield* Stream.runCollect(evens))\n *   })\n * )\n *\n * Effect.runPromise(program)\n * // { _id: 'Chunk', values: [ 1, 3, 5, 7, 9 ] }\n * // { _id: 'Chunk', values: [ 2, 4, 6, 8 ] }\n * ```\n *\n * @see {@link partitionEither} for partitioning a stream based on effectful\n * conditions.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const partition = internal.partition;\n/**\n * Splits a stream into two substreams based on an effectful condition.\n *\n * **Details**\n *\n * The `Stream.partitionEither` function is used to divide a stream into two\n * parts: one for elements that satisfy a condition producing `Either.left`\n * values, and another for those that produce `Either.right` values. This\n * function applies an effectful predicate to each element in the stream to\n * determine which substream it belongs to.\n *\n * The faster stream may advance up to `bufferSize` elements ahead of the slower\n * one.\n *\n * **Example** (Partitioning a Stream with an Effectful Predicate)\n *\n * ```ts\n * import { Effect, Either, Stream } from \"effect\"\n *\n * const partition = Stream.range(1, 9).pipe(\n *   Stream.partitionEither(\n *     (n) => Effect.succeed(n % 2 === 0 ? Either.right(n) : Either.left(n)),\n *     { bufferSize: 5 }\n *   )\n * )\n *\n * const program = Effect.scoped(\n *   Effect.gen(function*() {\n *     const [evens, odds] = yield* partition\n *     console.log(yield* Stream.runCollect(evens))\n *     console.log(yield* Stream.runCollect(odds))\n *   })\n * )\n *\n * Effect.runPromise(program)\n * // { _id: 'Chunk', values: [ 1, 3, 5, 7, 9 ] }\n * // { _id: 'Chunk', values: [ 2, 4, 6, 8 ] }\n * ```\n *\n * @see {@link partition} for partitioning a stream based on simple conditions.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const partitionEither = internal.partitionEither;\n/**\n * Peels off enough material from the stream to construct a `Z` using the\n * provided `Sink` and then returns both the `Z` and the rest of the\n * `Stream` in a scope. Like all scoped values, the provided stream is\n * valid only within the scope.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const peel = internal.peel;\n/**\n * Pipes all of the values from this stream through the provided sink.\n *\n * See also `Stream.transduce`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const pipeThrough = internal.pipeThrough;\n/**\n * Pipes all the values from this stream through the provided channel.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const pipeThroughChannel = internal.pipeThroughChannel;\n/**\n * Pipes all values from this stream through the provided channel, passing\n * through any error emitted by this stream unchanged.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const pipeThroughChannelOrFail = internal.pipeThroughChannelOrFail;\n/**\n * Emits the provided chunk before emitting any other value.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const prepend = internal.prepend;\n/**\n * Provides the stream with its required context, which eliminates its\n * dependency on `R`.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideContext = internal.provideContext;\n/**\n * Provides the stream with some of its required context, which eliminates its\n * dependency on `R`.\n *\n * @since 3.16.9\n * @category context\n */\nexport const provideSomeContext = internal.provideSomeContext;\n/**\n * Provides a `Layer` to the stream, which translates it to another level.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideLayer = internal.provideLayer;\n/**\n * Provides the stream with the single service it requires. If the stream\n * requires more than one service use `Stream.provideContext` instead.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideService = internal.provideService;\n/**\n * Provides the stream with the single service it requires. If the stream\n * requires more than one service use `Stream.provideContext` instead.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideServiceEffect = internal.provideServiceEffect;\n/**\n * Provides the stream with the single service it requires. If the stream\n * requires more than one service use `Stream.provideContext` instead.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideServiceStream = internal.provideServiceStream;\n/**\n * Transforms the context being provided to the stream with the specified\n * function.\n *\n * @since 2.0.0\n * @category context\n */\nexport const mapInputContext = internal.mapInputContext;\n/**\n * Splits the context into two parts, providing one part using the\n * specified layer and leaving the remainder `R0`.\n *\n * @since 2.0.0\n * @category context\n */\nexport const provideSomeLayer = internal.provideSomeLayer;\n/**\n * Returns a stream that mirrors the first upstream to emit an item.\n * As soon as one of the upstream emits a first value, the other is interrupted.\n * The resulting stream will forward all items from the \"winning\" source stream.\n * Any upstream failures will cause the returned stream to fail.\n *\n * @example\n * ```ts\n * import { Stream, Schedule, Console, Effect } from \"effect\"\n *\n * const stream = Stream.fromSchedule(Schedule.spaced('2 millis')).pipe(\n *   Stream.race(Stream.fromSchedule(Schedule.spaced('1 millis'))),\n *   Stream.take(6),\n *   Stream.tap(Console.log)\n * )\n *\n * Effect.runPromise(Stream.runDrain(stream))\n * // Output each millisecond from the first stream, the rest streams are interrupted\n * // 0\n * // 1\n * // 2\n * // 3\n * // 4\n * // 5\n * ```\n * @since 3.7.0\n * @category racing\n */\nexport const race = internal.race;\n/**\n * Returns a stream that mirrors the first upstream to emit an item.\n * As soon as one of the upstream emits a first value, all the others are interrupted.\n * The resulting stream will forward all items from the \"winning\" source stream.\n * Any upstream failures will cause the returned stream to fail.\n *\n * @example\n * ```ts\n * import { Stream, Schedule, Console, Effect } from \"effect\"\n *\n * const stream = Stream.raceAll(\n *   Stream.fromSchedule(Schedule.spaced('1 millis')),\n *   Stream.fromSchedule(Schedule.spaced('2 millis')),\n *   Stream.fromSchedule(Schedule.spaced('4 millis')),\n * ).pipe(Stream.take(6), Stream.tap(Console.log))\n *\n * Effect.runPromise(Stream.runDrain(stream))\n * // Output each millisecond from the first stream, the rest streams are interrupted\n * // 0\n * // 1\n * // 2\n * // 3\n * // 4\n * // 5\n * ```\n * @since 3.5.0\n * @category racing\n */\nexport const raceAll = internal.raceAll;\n/**\n * Constructs a stream from a range of integers, including both endpoints.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * // A Stream with a range of numbers from 1 to 5\n * const stream = Stream.range(1, 5)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3, 4, 5 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const range = internal.range;\n/**\n * Re-chunks the elements of the stream into chunks of `n` elements each. The\n * last chunk might contain less than `n` elements.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const rechunk = internal.rechunk;\n/**\n * Keeps some of the errors, and terminates the fiber with the rest\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const refineOrDie = internal.refineOrDie;\n/**\n * Keeps some of the errors, and terminates the fiber with the rest, using the\n * specified function to convert the `E` into a defect.\n *\n * @since 2.0.0\n * @category error handling\n */\nexport const refineOrDieWith = internal.refineOrDieWith;\n/**\n * Repeats the entire stream using the specified schedule. The stream will\n * execute normally, and then repeat again according to the provided schedule.\n *\n * @example\n * ```ts\n * import { Effect, Schedule, Stream } from \"effect\"\n *\n * const stream = Stream.repeat(Stream.succeed(1), Schedule.forever)\n *\n * Effect.runPromise(Stream.runCollect(stream.pipe(Stream.take(5)))).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 1, 1, 1, 1 ] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const repeat = internal.repeat;\n/**\n * Creates a stream from an effect producing a value of type `A` which repeats\n * forever.\n *\n * @example\n * ```ts\n * import { Effect, Random, Stream } from \"effect\"\n *\n * const stream = Stream.repeatEffect(Random.nextInt)\n *\n * Effect.runPromise(Stream.runCollect(stream.pipe(Stream.take(5)))).then(console.log)\n * // Example Output: { _id: 'Chunk', values: [ 3891571149, 4239494205, 2352981603, 2339111046, 1488052210 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const repeatEffect = internal.repeatEffect;\n/**\n * Creates a stream from an effect producing chunks of `A` values which\n * repeats forever.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const repeatEffectChunk = internal.repeatEffectChunk;\n/**\n * Creates a stream from an effect producing chunks of `A` values until it\n * fails with `None`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const repeatEffectChunkOption = internal.repeatEffectChunkOption;\n/**\n * Creates a stream from an effect producing values of type `A` until it fails\n * with `None`.\n *\n * @example\n * ```ts\n * // In this example, we're draining an Iterator to create a stream from it\n * import { Stream, Effect, Option } from \"effect\"\n *\n * const drainIterator = <A>(it: Iterator<A>): Stream.Stream<A> =>\n *   Stream.repeatEffectOption(\n *     Effect.sync(() => it.next()).pipe(\n *       Effect.andThen((res) => {\n *         if (res.done) {\n *           return Effect.fail(Option.none())\n *         }\n *         return Effect.succeed(res.value)\n *       })\n *     )\n *   )\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const repeatEffectOption = internal.repeatEffectOption;\n/**\n * Creates a stream from an effect producing a value of type `A`, which is\n * repeated using the specified schedule.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const repeatEffectWithSchedule = internal.repeatEffectWithSchedule;\n/**\n * Repeats the entire stream using the specified schedule. The stream will\n * execute normally, and then repeat again according to the provided schedule.\n * The schedule output will be emitted at the end of each repetition.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const repeatEither = internal.repeatEither;\n/**\n * Repeats each element of the stream using the provided schedule. Repetitions\n * are done in addition to the first execution, which means using\n * `Schedule.recurs(1)` actually results in the original effect, plus an\n * additional recurrence, for a total of two repetitions of each value in the\n * stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const repeatElements = internal.repeatElements;\n/**\n * Repeats each element of the stream using the provided schedule. When the\n * schedule is finished, then the output of the schedule will be emitted into\n * the stream. Repetitions are done in addition to the first execution, which\n * means using `Schedule.recurs(1)` actually results in the original effect,\n * plus an additional recurrence, for a total of two repetitions of each value\n * in the stream.\n *\n * This function accepts two conversion functions, which allow the output of\n * this stream and the output of the provided schedule to be unified into a\n * single type. For example, `Either` or similar data type.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const repeatElementsWith = internal.repeatElementsWith;\n/**\n * Repeats the provided value infinitely.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.repeatValue(0)\n *\n * Effect.runPromise(Stream.runCollect(stream.pipe(Stream.take(5)))).then(console.log)\n * // { _id: 'Chunk', values: [ 0, 0, 0, 0, 0 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const repeatValue = internal.repeatValue;\n/**\n * Repeats the entire stream using the specified schedule. The stream will\n * execute normally, and then repeat again according to the provided schedule.\n * The schedule output will be emitted at the end of each repetition and can\n * be unified with the stream elements using the provided functions.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const repeatWith = internal.repeatWith;\n/**\n * When the stream fails, retry it according to the given schedule\n *\n * This retries the entire stream, so will re-execute all of the stream's\n * acquire operations.\n *\n * The schedule is reset as soon as the first element passes through the\n * stream again.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const retry = internal.retry;\n/**\n * Apply an `ExecutionPlan` to the stream, which allows you to fallback to\n * different resources in case of failure.\n *\n * If you have a stream that could fail with partial results, you can use\n * the `preventFallbackOnPartialStream` option to prevent contamination of\n * the final stream with partial results.\n *\n * @since 3.16.0\n * @category Error handling\n * @experimental\n */\nexport const withExecutionPlan = internal.withExecutionPlan;\n/**\n * Runs the sink on the stream to produce either the sink's result or an error.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const run = internal.run;\n/**\n * Runs the stream and collects all of its elements to a chunk.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runCollect = internal.runCollect;\n/**\n * Runs the stream and emits the number of elements processed\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runCount = internal.runCount;\n/**\n * Runs the stream only for its effects. The emitted elements are discarded.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runDrain = internal.runDrain;\n/**\n * Executes a pure fold over the stream of values - reduces all elements in\n * the stream to a value of type `S`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFold = internal.runFold;\n/**\n * Executes an effectful fold over the stream of values.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFoldEffect = internal.runFoldEffect;\n/**\n * Executes a pure fold over the stream of values. Returns a scoped value that\n * represents the scope of the stream.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFoldScoped = internal.runFoldScoped;\n/**\n * Executes an effectful fold over the stream of values. Returns a scoped\n * value that represents the scope of the stream.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFoldScopedEffect = internal.runFoldScopedEffect;\n/**\n * Reduces the elements in the stream to a value of type `S`. Stops the fold\n * early when the condition is not fulfilled. Example:\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFoldWhile = internal.runFoldWhile;\n/**\n * Executes an effectful fold over the stream of values. Stops the fold early\n * when the condition is not fulfilled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFoldWhileEffect = internal.runFoldWhileEffect;\n/**\n * Executes a pure fold over the stream of values. Returns a scoped value that\n * represents the scope of the stream. Stops the fold early when the condition\n * is not fulfilled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFoldWhileScoped = internal.runFoldWhileScoped;\n/**\n * Executes an effectful fold over the stream of values. Returns a scoped\n * value that represents the scope of the stream. Stops the fold early when\n * the condition is not fulfilled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runFoldWhileScopedEffect = internal.runFoldWhileScopedEffect;\n/**\n * Consumes all elements of the stream, passing them to the specified\n * callback.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runForEach = internal.runForEach;\n/**\n * Consumes all elements of the stream, passing them to the specified\n * callback.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runForEachChunk = internal.runForEachChunk;\n/**\n * Like `Stream.runForEachChunk`, but returns a scoped effect so the\n * finalization order can be controlled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runForEachChunkScoped = internal.runForEachChunkScoped;\n/**\n * Like `Stream.forEach`, but returns a scoped effect so the finalization\n * order can be controlled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runForEachScoped = internal.runForEachScoped;\n/**\n * Consumes elements of the stream, passing them to the specified callback,\n * and terminating consumption when the callback returns `false`.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runForEachWhile = internal.runForEachWhile;\n/**\n * Like `Stream.runForEachWhile`, but returns a scoped effect so the\n * finalization order can be controlled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runForEachWhileScoped = internal.runForEachWhileScoped;\n/**\n * Runs the stream to completion and yields the first value emitted by it,\n * discarding the rest of the elements.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runHead = internal.runHead;\n/**\n * Publishes elements of this stream to a `PubSub`. Stream failure and ending will\n * also be signalled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runIntoPubSub = internal.runIntoPubSub;\n/**\n * Like `Stream.runIntoPubSub`, but provides the result as a scoped effect to\n * allow for scope composition.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runIntoPubSubScoped = internal.runIntoPubSubScoped;\n/**\n * Enqueues elements of this stream into a queue. Stream failure and ending\n * will also be signalled.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runIntoQueue = internal.runIntoQueue;\n/**\n * Like `Stream.runIntoQueue`, but provides the result as a scoped [[ZIO]]\n * to allow for scope composition.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runIntoQueueElementsScoped = internal.runIntoQueueElementsScoped;\n/**\n * Like `Stream.runIntoQueue`, but provides the result as a scoped effect\n * to allow for scope composition.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runIntoQueueScoped = internal.runIntoQueueScoped;\n/**\n * Runs the stream to completion and yields the last value emitted by it,\n * discarding the rest of the elements.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runLast = internal.runLast;\n/**\n * @since 2.0.0\n * @category destructors\n */\nexport const runScoped = internal.runScoped;\n/**\n * Runs the stream to a sink which sums elements, provided they are Numeric.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const runSum = internal.runSum;\n/**\n * Statefully maps over the elements of this stream to produce all\n * intermediate results of type `S` given an initial S.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.range(1, 6).pipe(Stream.scan(0, (a, b) => a + b))\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 0,  1,  3, 6, 10, 15, 21 ] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const scan = internal.scan;\n/**\n * Statefully and effectfully maps over the elements of this stream to produce\n * all intermediate results of type `S` given an initial S.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const scanEffect = internal.scanEffect;\n/**\n * Statefully maps over the elements of this stream to produce all\n * intermediate results.\n *\n * See also `Stream.scan`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const scanReduce = internal.scanReduce;\n/**\n * Statefully and effectfully maps over the elements of this stream to produce\n * all intermediate results.\n *\n * See also `Stream.scanEffect`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const scanReduceEffect = internal.scanReduceEffect;\n/**\n * Schedules the output of the stream using the provided `schedule`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const schedule = internal.schedule;\n/**\n * Schedules the output of the stream using the provided `schedule` and emits\n * its output at the end (if `schedule` is finite). Uses the provided function\n * to align the stream and schedule outputs on the same type.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const scheduleWith = internal.scheduleWith;\n/**\n * Creates a single-valued stream from a scoped resource.\n *\n * @example\n * ```ts\n * import { Console, Effect, Stream } from \"effect\"\n *\n * // Creating a single-valued stream from a scoped resource\n * const stream = Stream.scoped(\n *  Effect.acquireRelease(\n *    Console.log(\"acquire\"),\n *    () => Console.log(\"release\")\n *  )\n * ).pipe(\n *  Stream.flatMap(() => Console.log(\"use\"))\n * )\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // acquire\n * // use\n * // release\n * // { _id: 'Chunk', values: [ undefined ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const scoped = internal.scoped;\n/**\n * Use a function that receives a scope and returns an effect to emit an output\n * element. The output element will be the result of the returned effect, if\n * successful.\n *\n * @since 3.11.0\n * @category constructors\n */\nexport const scopedWith = internal.scopedWith;\n/**\n * Emits a sliding window of `n` elements.\n *\n * ```ts\n * import { pipe, Stream } from \"effect\"\n *\n * pipe(\n *   Stream.make(1, 2, 3, 4),\n *   Stream.sliding(2),\n *   Stream.runCollect\n * )\n * // => Chunk(Chunk(1, 2), Chunk(2, 3), Chunk(3, 4))\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const sliding = internal.sliding;\n/**\n * Like `sliding`, but with a configurable `stepSize` parameter.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const slidingSize = internal.slidingSize;\n/**\n * Converts an option on values into an option on errors.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const some = internal.some;\n/**\n * Extracts the optional value, or returns the given 'default'.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const someOrElse = internal.someOrElse;\n/**\n * Extracts the optional value, or fails with the given error 'e'.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const someOrFail = internal.someOrFail;\n/**\n * Splits elements based on a predicate or refinement.\n *\n * ```ts\n * import { pipe, Stream } from \"effect\"\n *\n * pipe(\n *   Stream.range(1, 10),\n *   Stream.split((n) => n % 4 === 0),\n *   Stream.runCollect\n * )\n * // => Chunk(Chunk(1, 2, 3), Chunk(5, 6, 7), Chunk(9))\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const split = internal.split;\n/**\n * Splits elements on a delimiter and transforms the splits into desired output.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const splitOnChunk = internal.splitOnChunk;\n/**\n * Splits strings on newlines. Handles both Windows newlines (`\\r\\n`) and UNIX\n * newlines (`\\n`).\n *\n * @since 2.0.0\n * @category combinators\n */\nexport const splitLines = internal.splitLines;\n/**\n * Creates a single-valued pure stream.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * // A Stream with a single number\n * const stream = Stream.succeed(3)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 3 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const succeed = internal.succeed;\n/**\n * Creates a single-valued pure stream.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const sync = internal.sync;\n/**\n * Returns a lazily constructed stream.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const suspend = internal.suspend;\n/**\n * Takes the specified number of elements from this stream.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.take(Stream.iterate(0, (n) => n + 1), 5)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 0, 1, 2, 3, 4 ] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const take = internal.take;\n/**\n * Takes the last specified number of elements from this stream.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.takeRight(Stream.make(1, 2, 3, 4, 5, 6), 3)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 4, 5, 6 ] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const takeRight = internal.takeRight;\n/**\n * Takes all elements of the stream until the specified predicate evaluates to\n * `true`.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.takeUntil(Stream.iterate(0, (n) => n + 1), (n) => n === 4)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 0, 1, 2, 3, 4 ] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const takeUntil = internal.takeUntil;\n/**\n * Takes all elements of the stream until the specified effectual predicate\n * evaluates to `true`.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const takeUntilEffect = internal.takeUntilEffect;\n/**\n * Takes all elements of the stream for as long as the specified predicate\n * evaluates to `true`.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.takeWhile(Stream.iterate(0, (n) => n + 1), (n) => n < 5)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ 0, 1, 2, 3, 4 ] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const takeWhile = internal.takeWhile;\n/**\n * Adds an effect to consumption of every element of the stream.\n *\n * @example\n * ```ts\n * import { Console, Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(1, 2, 3).pipe(\n *   Stream.tap((n) => Console.log(`before mapping: ${n}`)),\n *   Stream.map((n) => n * 2),\n *   Stream.tap((n) => Console.log(`after mapping: ${n}`))\n * )\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // before mapping: 1\n * // after mapping: 2\n * // before mapping: 2\n * // after mapping: 4\n * // before mapping: 3\n * // after mapping: 6\n * // { _id: 'Chunk', values: [ 2, 4, 6 ] }\n * ```\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tap = internal.tap;\n/**\n * Returns a stream that effectfully \"peeks\" at the failure or success of\n * the stream.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapBoth = internal.tapBoth;\n/**\n * Returns a stream that effectfully \"peeks\" at the failure of the stream.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapError = internal.tapError;\n/**\n * Returns a stream that effectfully \"peeks\" at the cause of failure of the\n * stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const tapErrorCause = internal.tapErrorCause;\n/**\n * Sends all elements emitted by this stream to the specified sink in addition\n * to emitting them.\n *\n * @since 2.0.0\n * @category sequencing\n */\nexport const tapSink = internal.tapSink;\n/**\n * Delays the chunks of this stream according to the given bandwidth\n * parameters using the token bucket algorithm. Allows for burst in the\n * processing of elements by allowing the token bucket to accumulate tokens up\n * to a `units + burst` threshold. The weight of each chunk is determined by\n * the `cost` function.\n *\n * If using the \"enforce\" strategy, chunks that do not meet the bandwidth\n * constraints are dropped. If using the \"shape\" strategy, chunks are delayed\n * until they can be emitted without exceeding the bandwidth constraints.\n *\n * Defaults to the \"shape\" strategy.\n *\n * @example\n * ```ts\n * import { Chunk, Effect, Schedule, Stream } from \"effect\"\n *\n * let last = Date.now()\n * const log = (message: string) =>\n *   Effect.sync(() => {\n *     const end = Date.now()\n *     console.log(`${message} after ${end - last}ms`)\n *     last = end\n *   })\n *\n * const stream = Stream.fromSchedule(Schedule.spaced(\"50 millis\")).pipe(\n *   Stream.take(6),\n *   Stream.tap((n) => log(`Received ${n}`)),\n *   Stream.throttle({\n *     cost: Chunk.size,\n *     duration: \"100 millis\",\n *     units: 1\n *   }),\n *   Stream.tap((n) => log(`> Emitted ${n}`))\n * )\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // Received 0 after 56ms\n * // > Emitted 0 after 0ms\n * // Received 1 after 52ms\n * // > Emitted 1 after 48ms\n * // Received 2 after 52ms\n * // > Emitted 2 after 49ms\n * // Received 3 after 52ms\n * // > Emitted 3 after 48ms\n * // Received 4 after 52ms\n * // > Emitted 4 after 47ms\n * // Received 5 after 52ms\n * // > Emitted 5 after 49ms\n * // { _id: 'Chunk', values: [ 0, 1, 2, 3, 4, 5 ] }\n * ```\n *\n * @since 2.0.0\n * @category utils\n */\nexport const throttle = internal.throttle;\n/**\n * Delays the chunks of this stream according to the given bandwidth\n * parameters using the token bucket algorithm. Allows for burst in the\n * processing of elements by allowing the token bucket to accumulate tokens up\n * to a `units + burst` threshold. The weight of each chunk is determined by\n * the effectful `costFn` function.\n *\n * If using the \"enforce\" strategy, chunks that do not meet the bandwidth\n * constraints are dropped. If using the \"shape\" strategy, chunks are delayed\n * until they can be emitted without exceeding the bandwidth constraints.\n *\n * Defaults to the \"shape\" strategy.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const throttleEffect = internal.throttleEffect;\n/**\n * A stream that emits void values spaced by the specified duration.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * let last = Date.now()\n * const log = (message: string) =>\n *   Effect.sync(() => {\n *     const end = Date.now()\n *     console.log(`${message} after ${end - last}ms`)\n *     last = end\n *   })\n *\n * const stream = Stream.tick(\"1 seconds\").pipe(Stream.tap(() => log(\"tick\")))\n *\n * Effect.runPromise(Stream.runCollect(stream.pipe(Stream.take(5)))).then(console.log)\n * // tick after 4ms\n * // tick after 1003ms\n * // tick after 1001ms\n * // tick after 1002ms\n * // tick after 1002ms\n * // { _id: 'Chunk', values: [ undefined, undefined, undefined, undefined, undefined ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const tick = internal.tick;\n/**\n * Ends the stream if it does not produce a value after the specified duration.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const timeout = internal.timeout;\n/**\n * Fails the stream with given error if it does not produce a value after d\n * duration.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const timeoutFail = internal.timeoutFail;\n/**\n * Fails the stream with given cause if it does not produce a value after d\n * duration.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const timeoutFailCause = internal.timeoutFailCause;\n/**\n * Switches the stream if it does not produce a value after the specified\n * duration.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const timeoutTo = internal.timeoutTo;\n/**\n * Converts the stream to a scoped `PubSub` of chunks. After the scope is closed,\n * the `PubSub` will never again produce values and should be discarded.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toPubSub = internal.toPubSub;\n/**\n * Returns in a scope a ZIO effect that can be used to repeatedly pull chunks\n * from the stream. The pull effect fails with None when the stream is\n * finished, or with Some error if it fails, otherwise it returns a chunk of\n * the stream's output.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * // Simulate a chunked stream\n * const stream = Stream.fromIterable([1, 2, 3, 4, 5]).pipe(Stream.rechunk(2))\n *\n * const program = Effect.gen(function*() {\n *   // Create an effect to get data chunks from the stream\n *   const getChunk = yield* Stream.toPull(stream)\n *\n *   // Continuously fetch and process chunks\n *   while (true) {\n *     const chunk = yield* getChunk\n *     console.log(chunk)\n *   }\n * })\n *\n * Effect.runPromise(Effect.scoped(program)).then(console.log, console.error)\n * // { _id: 'Chunk', values: [ 1, 2 ] }\n * // { _id: 'Chunk', values: [ 3, 4 ] }\n * // { _id: 'Chunk', values: [ 5 ] }\n * // (FiberFailure) Error: {\n * //   \"_id\": \"Option\",\n * //   \"_tag\": \"None\"\n * // }\n * ```\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toPull = internal.toPull;\n/**\n * Converts the stream to a scoped queue of chunks. After the scope is closed,\n * the queue will never again produce values and should be discarded.\n *\n * Defaults to the \"suspend\" back pressure strategy with a capacity of 2.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toQueue = internal.toQueue;\n/**\n * Converts the stream to a scoped queue of elements. After the scope is\n * closed, the queue will never again produce values and should be discarded.\n *\n * Defaults to a capacity of 2.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toQueueOfElements = internal.toQueueOfElements;\n/**\n * Converts the stream to a `ReadableStream`.\n *\n * See https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toReadableStream = internal.toReadableStream;\n/**\n * Converts the stream to a `Effect<ReadableStream>`.\n *\n * See https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toReadableStreamEffect = internal.toReadableStreamEffect;\n/**\n * Converts the stream to a `ReadableStream` using the provided runtime.\n *\n * See https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream.\n *\n * @since 2.0.0\n * @category destructors\n */\nexport const toReadableStreamRuntime = internal.toReadableStreamRuntime;\n/**\n * Converts the stream to a `AsyncIterable` using the provided runtime.\n *\n * @since 3.15.0\n * @category destructors\n */\nexport const toAsyncIterableRuntime = internal.toAsyncIterableRuntime;\n/**\n * Converts the stream to a `AsyncIterable` capturing the required dependencies.\n *\n * @since 3.15.0\n * @category destructors\n */\nexport const toAsyncIterableEffect = internal.toAsyncIterableEffect;\n/**\n * Converts the stream to a `AsyncIterable`.\n *\n * @since 3.15.0\n * @category destructors\n */\nexport const toAsyncIterable = internal.toAsyncIterable;\n/**\n * Applies the transducer to the stream and emits its outputs.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const transduce = internal.transduce;\n/**\n * Creates a stream by peeling off the \"layers\" of a value of type `S`.\n *\n * @example\n * ```ts\n * import { Effect, Option, Stream } from \"effect\"\n *\n * const stream = Stream.unfold(1, (n) => Option.some([n, n + 1]))\n *\n * Effect.runPromise(Stream.runCollect(stream.pipe(Stream.take(5)))).then(console.log)\n * // { _id: 'Chunk', values: [ 1, 2, 3, 4, 5 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unfold = internal.unfold;\n/**\n * Creates a stream by peeling off the \"layers\" of a value of type `S`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unfoldChunk = internal.unfoldChunk;\n/**\n * Creates a stream by effectfully peeling off the \"layers\" of a value of type\n * `S`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unfoldChunkEffect = internal.unfoldChunkEffect;\n/**\n * Creates a stream by effectfully peeling off the \"layers\" of a value of type\n * `S`.\n *\n * @example\n * ```ts\n * import { Effect, Option, Random, Stream } from \"effect\"\n *\n * const stream = Stream.unfoldEffect(1, (n) =>\n *   Random.nextBoolean.pipe(\n *     Effect.map((b) => (b ? Option.some([n, -n]) : Option.some([n, n])))\n *   ))\n *\n * Effect.runPromise(Stream.runCollect(stream.pipe(Stream.take(5)))).then(console.log)\n * // { _id: 'Chunk', values: [ 1, -1, -1, -1, -1 ] }\n * ```\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unfoldEffect = internal.unfoldEffect;\nconst void_ = internal.void;\nexport {\n/**\n * A stream that contains a single `void` value.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.void\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ undefined ] }\n *\n * ```\n * @since 2.0.0\n * @category constructors\n */\nvoid_ as void };\n/**\n * Creates a stream produced from an `Effect`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unwrap = internal.unwrap;\n/**\n * Creates a stream produced from a scoped `Effect`.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const unwrapScoped = internal.unwrapScoped;\n/**\n * Creates a stream produced from a function which receives a `Scope` and\n * returns an `Effect`. The resulting stream will emit a single element, which\n * will be the result of the returned effect, if successful.\n *\n * @since 3.11.0\n * @category constructors\n */\nexport const unwrapScopedWith = internal.unwrapScopedWith;\n/**\n * Updates the specified service within the context of the `Stream`.\n *\n * @since 2.0.0\n * @category context\n */\nexport const updateService = internal.updateService;\n/**\n * Returns the specified stream if the given condition is satisfied, otherwise\n * returns an empty stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const when = internal.when;\n/**\n * Returns the resulting stream when the given `PartialFunction` is defined\n * for the given value, otherwise returns an empty stream.\n *\n * @since 2.0.0\n * @category constructors\n */\nexport const whenCase = internal.whenCase;\n/**\n * Returns the stream when the given partial function is defined for the given\n * effectful value, otherwise returns an empty stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const whenCaseEffect = internal.whenCaseEffect;\n/**\n * Returns the stream if the given effectful condition is satisfied, otherwise\n * returns an empty stream.\n *\n * @since 2.0.0\n * @category utils\n */\nexport const whenEffect = internal.whenEffect;\n/**\n * Wraps the stream with a new span for tracing.\n *\n * @since 2.0.0\n * @category tracing\n */\nexport const withSpan = internal.withSpan;\n/**\n * Zips this stream with another point-wise and emits tuples of elements from\n * both streams.\n *\n * The new stream will end when one of the sides ends.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * // We create two streams and zip them together.\n * const stream = Stream.zip(\n *   Stream.make(1, 2, 3, 4, 5, 6),\n *   Stream.make(\"a\", \"b\", \"c\")\n * )\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ [ 1, 'a' ], [ 2, 'b' ], [ 3, 'c' ] ] }\n * ```\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zip = internal.zip;\n/**\n * Zips this stream with another point-wise and emits tuples of elements from\n * both streams.\n *\n * The new stream will end when one of the sides ends.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipFlatten = internal.zipFlatten;\n/**\n * Zips this stream with another point-wise, creating a new stream of pairs of\n * elements from both sides.\n *\n * The defaults `defaultLeft` and `defaultRight` will be used if the streams\n * have different lengths and one of the streams has ended before the other.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.zipAll(Stream.make(1, 2, 3, 4, 5, 6), {\n *   other: Stream.make(\"a\", \"b\", \"c\"),\n *   defaultSelf: 0,\n *   defaultOther: \"x\"\n * })\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: \"Chunk\", values: [ [ 1, \"a\" ], [ 2, \"b\" ], [ 3, \"c\" ], [ 4, \"x\" ], [ 5, \"x\" ], [ 6, \"x\" ] ] }\n * ```\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAll = internal.zipAll;\n/**\n * Zips this stream with another point-wise, and keeps only elements from this\n * stream.\n *\n * The provided default value will be used if the other stream ends before\n * this one.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAllLeft = internal.zipAllLeft;\n/**\n * Zips this stream with another point-wise, and keeps only elements from the\n * other stream.\n *\n * The provided default value will be used if this stream ends before the\n * other one.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAllRight = internal.zipAllRight;\n/**\n * Zips this stream that is sorted by distinct keys and the specified stream\n * that is sorted by distinct keys to produce a new stream that is sorted by\n * distinct keys. Combines values associated with each key into a tuple,\n * using the specified values `defaultLeft` and `defaultRight` to fill in\n * missing values.\n *\n * This allows zipping potentially unbounded streams of data by key in\n * constant space but the caller is responsible for ensuring that the\n * streams are sorted by distinct keys.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAllSortedByKey = internal.zipAllSortedByKey;\n/**\n * Zips this stream that is sorted by distinct keys and the specified stream\n * that is sorted by distinct keys to produce a new stream that is sorted by\n * distinct keys. Keeps only values from this stream, using the specified\n * value `default` to fill in missing values.\n *\n * This allows zipping potentially unbounded streams of data by key in\n * constant space but the caller is responsible for ensuring that the\n * streams are sorted by distinct keys.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAllSortedByKeyLeft = internal.zipAllSortedByKeyLeft;\n/**\n * Zips this stream that is sorted by distinct keys and the specified stream\n * that is sorted by distinct keys to produce a new stream that is sorted by\n * distinct keys. Keeps only values from that stream, using the specified\n * value `default` to fill in missing values.\n *\n * This allows zipping potentially unbounded streams of data by key in\n * constant space but the caller is responsible for ensuring that the\n * streams are sorted by distinct keys.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAllSortedByKeyRight = internal.zipAllSortedByKeyRight;\n/**\n * Zips this stream that is sorted by distinct keys and the specified stream\n * that is sorted by distinct keys to produce a new stream that is sorted by\n * distinct keys. Uses the functions `left`, `right`, and `both` to handle\n * the cases where a key and value exist in this stream, that stream, or\n * both streams.\n *\n * This allows zipping potentially unbounded streams of data by key in\n * constant space but the caller is responsible for ensuring that the\n * streams are sorted by distinct keys.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAllSortedByKeyWith = internal.zipAllSortedByKeyWith;\n/**\n * Zips this stream with another point-wise. The provided functions will be\n * used to create elements for the composed stream.\n *\n * The functions `left` and `right` will be used if the streams have different\n * lengths and one of the streams has ended before the other.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.zipAllWith(Stream.make(1, 2, 3, 4, 5, 6), {\n *   other: Stream.make(\"a\", \"b\", \"c\"),\n *   onSelf: (n) => [n, \"x\"],\n *   onOther: (s) => [0, s],\n *   onBoth: (n, s) => [n - s.length, s]\n * })\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: \"Chunk\", values: [ [ 0, \"a\" ], [ 1, \"b\" ], [ 2, \"c\" ], [ 4, \"x\" ], [ 5, \"x\" ], [ 6, \"x\" ] ] }\n * ```\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipAllWith = internal.zipAllWith;\n/**\n * Zips the two streams so that when a value is emitted by either of the two\n * streams, it is combined with the latest value from the other stream to\n * produce a result.\n *\n * Note: tracking the latest value is done on a per-chunk basis. That means\n * that emitted elements that are not the last value in chunks will never be\n * used for zipping.\n *\n * @example\n * ```ts\n * import { Effect, Schedule, Stream } from \"effect\"\n *\n * const s1 = Stream.make(1, 2, 3).pipe(\n *   Stream.schedule(Schedule.spaced(\"1 second\"))\n * )\n *\n * const s2 = Stream.make(\"a\", \"b\", \"c\", \"d\").pipe(\n *   Stream.schedule(Schedule.spaced(\"500 millis\"))\n * )\n *\n * const stream = Stream.zipLatest(s1, s2)\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: \"Chunk\", values: [ [ 1, \"a\" ], [ 1, \"b\" ], [ 2, \"b\" ], [ 2, \"c\" ], [ 2, \"d\" ], [ 3, \"d\" ] ] }\n * ```\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipLatest = internal.zipLatest;\n/**\n * Zips multiple streams so that when a value is emitted by any of the streams,\n * it is combined with the latest values from the other streams to produce a result.\n *\n * Note: tracking the latest value is done on a per-chunk basis. That means\n * that emitted elements that are not the last value in chunks will never be\n * used for zipping.\n *\n * @example\n * ```ts\n * import { Stream, Schedule, Console, Effect } from \"effect\"\n *\n * const stream = Stream.zipLatestAll(\n *     Stream.fromSchedule(Schedule.spaced('1 millis')),\n *     Stream.fromSchedule(Schedule.spaced('2 millis')),\n *     Stream.fromSchedule(Schedule.spaced('4 millis')),\n * ).pipe(Stream.take(6), Stream.tap(Console.log))\n *\n * Effect.runPromise(Stream.runDrain(stream))\n * // Output:\n * // [ 0, 0, 0 ]\n * // [ 1, 0, 0 ]\n * // [ 1, 1, 0 ]\n * // [ 2, 1, 0 ]\n * // [ 3, 1, 0 ]\n * // [ 3, 1, 1 ]\n * // .....\n * ```\n *\n * @since 3.3.0\n * @category zipping\n */\nexport const zipLatestAll = internal.zipLatestAll;\n/**\n * Zips the two streams so that when a value is emitted by either of the two\n * streams, it is combined with the latest value from the other stream to\n * produce a result.\n *\n * Note: tracking the latest value is done on a per-chunk basis. That means\n * that emitted elements that are not the last value in chunks will never be\n * used for zipping.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipLatestWith = internal.zipLatestWith;\n/**\n * Zips this stream with another point-wise, but keeps only the outputs of\n * `left` stream.\n *\n * The new stream will end when one of the sides ends.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipLeft = internal.zipLeft;\n/**\n * Zips this stream with another point-wise, but keeps only the outputs of the\n * `right` stream.\n *\n * The new stream will end when one of the sides ends.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipRight = internal.zipRight;\n/**\n * Zips this stream with another point-wise and applies the function to the\n * paired elements.\n *\n * The new stream will end when one of the sides ends.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * // We create two streams and zip them with custom logic.\n * const stream = Stream.zipWith(\n *   Stream.make(1, 2, 3, 4, 5, 6),\n *   Stream.make(\"a\", \"b\", \"c\"),\n *   (n, s) => [n - s.length, s]\n * )\n *\n * Effect.runPromise(Stream.runCollect(stream)).then(console.log)\n * // { _id: 'Chunk', values: [ [ 0, 'a' ], [ 1, 'b' ], [ 2, 'c' ] ] }\n * ```\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWith = internal.zipWith;\n/**\n * Zips this stream with another point-wise and applies the function to the\n * paired elements.\n *\n * The new stream will end when one of the sides ends.\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWithChunks = internal.zipWithChunks;\n/**\n * Zips each element with the next element if present.\n *\n * @example\n * ```ts\n * import { Chunk, Effect, Stream } from \"effect\"\n *\n * const stream = Stream.zipWithNext(Stream.make(1, 2, 3, 4))\n *\n * Effect.runPromise(Stream.runCollect(stream)).then((chunk) => console.log(Chunk.toArray(chunk)))\n * // [\n * //   [ 1, { _id: 'Option', _tag: 'Some', value: 2 } ],\n * //   [ 2, { _id: 'Option', _tag: 'Some', value: 3 } ],\n * //   [ 3, { _id: 'Option', _tag: 'Some', value: 4 } ],\n * //   [ 4, { _id: 'Option', _tag: 'None' } ]\n * // ]\n * ```\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWithNext = internal.zipWithNext;\n/**\n * Zips each element with the previous element. Initially accompanied by\n * `None`.\n *\n * @example\n * ```ts\n * import { Chunk, Effect, Stream } from \"effect\"\n *\n * const stream = Stream.zipWithPrevious(Stream.make(1, 2, 3, 4))\n *\n * Effect.runPromise(Stream.runCollect(stream)).then((chunk) => console.log(Chunk.toArray(chunk)))\n * // [\n * //   [ { _id: 'Option', _tag: 'None' }, 1 ],\n * //   [ { _id: 'Option', _tag: 'Some', value: 1 }, 2 ],\n * //   [ { _id: 'Option', _tag: 'Some', value: 2 }, 3 ],\n * //   [ { _id: 'Option', _tag: 'Some', value: 3 }, 4 ]\n * // ]\n * ```\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWithPrevious = internal.zipWithPrevious;\n/**\n * Zips each element with both the previous and next element.\n *\n * @example\n * ```ts\n * import { Chunk, Effect, Stream } from \"effect\"\n *\n * const stream = Stream.zipWithPreviousAndNext(Stream.make(1, 2, 3, 4))\n *\n * Effect.runPromise(Stream.runCollect(stream)).then((chunk) => console.log(Chunk.toArray(chunk)))\n * // [\n * //   [\n * //     { _id: 'Option', _tag: 'None' },\n * //     1,\n * //     { _id: 'Option', _tag: 'Some', value: 2 }\n * //   ],\n * //   [\n * //     { _id: 'Option', _tag: 'Some', value: 1 },\n * //     2,\n * //     { _id: 'Option', _tag: 'Some', value: 3 }\n * //   ],\n * //   [\n * //     { _id: 'Option', _tag: 'Some', value: 2 },\n * //     3,\n * //     { _id: 'Option', _tag: 'Some', value: 4 }\n * //   ],\n * //   [\n * //     { _id: 'Option', _tag: 'Some', value: 3 },\n * //     4,\n * //     { _id: 'Option', _tag: 'None' }\n * //   ]\n * // ]\n * ```\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWithPreviousAndNext = internal.zipWithPreviousAndNext;\n/**\n * Zips this stream together with the index of elements.\n *\n * @example\n * ```ts\n * import { Effect, Stream } from \"effect\"\n *\n * const stream = Stream.make(\"Mary\", \"James\", \"Robert\", \"Patricia\")\n *\n * const indexedStream = Stream.zipWithIndex(stream)\n *\n * Effect.runPromise(Stream.runCollect(indexedStream)).then(console.log)\n * // {\n * //   _id: 'Chunk',\n * //   values: [ [ 'Mary', 0 ], [ 'James', 1 ], [ 'Robert', 2 ], [ 'Patricia', 3 ] ]\n * // }\n * ```\n *\n * @since 2.0.0\n * @category zipping\n */\nexport const zipWithIndex = internal.zipWithIndex;\n// -------------------------------------------------------------------------------------\n// do notation\n// -------------------------------------------------------------------------------------\n/**\n * The \"do simulation\" in Effect allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Stream` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @example\n * ```ts\n * import * as assert from \"node:assert\"\n * import { Chunk, Effect, pipe, Stream } from \"effect\"\n *\n * const result = pipe(\n *   Stream.Do,\n *   Stream.bind(\"x\", () => Stream.succeed(2)),\n *   Stream.bind(\"y\", () => Stream.succeed(3)),\n *   Stream.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(Effect.runSync(Stream.runCollect(result)), Chunk.of({ x: 2, y: 3, sum: 5 }))\n * ```\n *\n * @see {@link bindTo}\n * @see {@link bind}\n * @see {@link bindEffect}\n * @see {@link let_ let}\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const Do = internal.Do;\n/**\n * The \"do simulation\" in Effect allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Stream` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @example\n * ```ts\n * import * as assert from \"node:assert\"\n * import { Chunk, Effect, pipe, Stream } from \"effect\"\n *\n * const result = pipe(\n *   Stream.Do,\n *   Stream.bind(\"x\", () => Stream.succeed(2)),\n *   Stream.bind(\"y\", () => Stream.succeed(3)),\n *   Stream.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(Effect.runSync(Stream.runCollect(result)), Chunk.of({ x: 2, y: 3, sum: 5 }))\n * ```\n *\n * @see {@link Do}\n * @see {@link bindTo}\n * @see {@link bindEffect}\n * @see {@link let_ let}\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const bind = internal.bind;\n/**\n * Binds an effectful value in a `do` scope\n *\n * @see {@link Do}\n * @see {@link bindTo}\n * @see {@link bind}\n * @see {@link let_ let}\n *\n * @since 2.0.0\n * @category do notation\n */\nexport const bindEffect = groupBy_.bindEffect;\n/**\n * The \"do simulation\" in Effect allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Stream` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @example\n * ```ts\n * import * as assert from \"node:assert\"\n * import { Chunk, Effect, pipe, Stream } from \"effect\"\n *\n * const result = pipe(\n *   Stream.Do,\n *   Stream.bind(\"x\", () => Stream.succeed(2)),\n *   Stream.bind(\"y\", () => Stream.succeed(3)),\n *   Stream.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(Effect.runSync(Stream.runCollect(result)), Chunk.of({ x: 2, y: 3, sum: 5 }))\n * ```\n *\n * @see {@link Do}\n * @see {@link bind}\n * @see {@link bindEffect}\n * @see {@link let_ let}\n *\n * @category do notation\n * @since 2.0.0\n */\nexport const bindTo = internal.bindTo;\nconst let_ = internal.let_;\nexport {\n/**\n * The \"do simulation\" in Effect allows you to write code in a more declarative style, similar to the \"do notation\" in other programming languages. It provides a way to define variables and perform operations on them using functions like `bind` and `let`.\n *\n * Here's how the do simulation works:\n *\n * 1. Start the do simulation using the `Do` value\n * 2. Within the do simulation scope, you can use the `bind` function to define variables and bind them to `Stream` values\n * 3. You can accumulate multiple `bind` statements to define multiple variables within the scope\n * 4. Inside the do simulation scope, you can also use the `let` function to define variables and bind them to simple values\n *\n * @example\n * ```ts\n * import * as assert from \"node:assert\"\n * import { Chunk, Effect, pipe, Stream } from \"effect\"\n *\n * const result = pipe(\n *   Stream.Do,\n *   Stream.bind(\"x\", () => Stream.succeed(2)),\n *   Stream.bind(\"y\", () => Stream.succeed(3)),\n *   Stream.let(\"sum\", ({ x, y }) => x + y)\n * )\n * assert.deepStrictEqual(Effect.runSync(Stream.runCollect(result)), Chunk.of({ x: 2, y: 3, sum: 5 }))\n * ```\n *\n * @see {@link Do}\n * @see {@link bindTo}\n * @see {@link bind}\n * @see {@link bindEffect}\n *\n * @category do notation\n * @since 2.0.0\n */\nlet_ as let };\n// -------------------------------------------------------------------------------------\n// encoding\n// -------------------------------------------------------------------------------------\n/**\n * Decode Uint8Array chunks into a stream of strings using the specified encoding.\n *\n * @since 2.0.0\n * @category encoding\n */\nexport const decodeText = internal.decodeText;\n/**\n * Encode a stream of strings into a stream of Uint8Array chunks using the specified encoding.\n *\n * @since 2.0.0\n * @category encoding\n */\nexport const encodeText = internal.encodeText;\n/**\n * Creates a `Stream` using addEventListener.\n * @since 3.1.0\n */\nexport const fromEventListener = internal.fromEventListener;\n//# sourceMappingURL=Stream.js.map",
      "start": 1768772628416,
      "end": 1768772628416
    },
    {
      "name": "sentry-vite-component-name-annotate-plugin",
      "start": 1768772628416,
      "end": 1768772628416,
      "order": "pre"
    },
    {
      "name": "comlink",
      "start": 1768772628419,
      "end": 1768772628421,
      "order": "normal"
    },
    {
      "name": "sentry-vite-bundle-size-optimizations-plugin",
      "start": 1768772628436,
      "end": 1768772628437,
      "order": "normal"
    },
    {
      "name": "vite-plugin-csp-guard",
      "start": 1768772628478,
      "end": 1768772628479,
      "order": "post-post"
    }
  ]
}
