{
  "resolvedId": "/home/wombocombo/github/wrk/gdg-fsc-website/node_modules/effect/dist/esm/internal/sink.js",
  "transforms": [
    {
      "name": "__load__",
      "result": "import * as Arr from \"../Array.js\";\nimport * as Cause from \"../Cause.js\";\nimport * as Chunk from \"../Chunk.js\";\nimport * as Clock from \"../Clock.js\";\nimport * as Duration from \"../Duration.js\";\nimport * as Effect from \"../Effect.js\";\nimport * as Either from \"../Either.js\";\nimport * as Exit from \"../Exit.js\";\nimport { constTrue, dual, identity, pipe } from \"../Function.js\";\nimport * as HashMap from \"../HashMap.js\";\nimport * as HashSet from \"../HashSet.js\";\nimport * as Option from \"../Option.js\";\nimport { pipeArguments } from \"../Pipeable.js\";\nimport { hasProperty } from \"../Predicate.js\";\nimport * as PubSub from \"../PubSub.js\";\nimport * as Queue from \"../Queue.js\";\nimport * as Ref from \"../Ref.js\";\nimport * as Scope from \"../Scope.js\";\nimport * as channel from \"./channel.js\";\nimport * as mergeDecision from \"./channel/mergeDecision.js\";\nimport * as core from \"./core-stream.js\";\n/** @internal */\nexport const SinkTypeId = /*#__PURE__*/Symbol.for(\"effect/Sink\");\nconst sinkVariance = {\n  /* c8 ignore next */\n  _A: _ => _,\n  /* c8 ignore next */\n  _In: _ => _,\n  /* c8 ignore next */\n  _L: _ => _,\n  /* c8 ignore next */\n  _E: _ => _,\n  /* c8 ignore next */\n  _R: _ => _\n};\n/** @internal */\nexport class SinkImpl {\n  channel;\n  [SinkTypeId] = sinkVariance;\n  constructor(channel) {\n    this.channel = channel;\n  }\n  pipe() {\n    return pipeArguments(this, arguments);\n  }\n}\n/** @internal */\nexport const isSink = u => hasProperty(u, SinkTypeId);\n/** @internal */\nexport const suspend = evaluate => new SinkImpl(core.suspend(() => toChannel(evaluate())));\n/** @internal */\nexport const as = /*#__PURE__*/dual(2, (self, a) => pipe(self, map(() => a)));\n/** @internal */\nexport const collectAll = () => new SinkImpl(collectAllLoop(Chunk.empty()));\n/** @internal */\nconst collectAllLoop = acc => core.readWithCause({\n  onInput: chunk => collectAllLoop(pipe(acc, Chunk.appendAll(chunk))),\n  onFailure: core.failCause,\n  onDone: () => core.succeed(acc)\n});\n/** @internal */\nexport const collectAllN = n => suspend(() => fromChannel(collectAllNLoop(n, Chunk.empty())));\n/** @internal */\nconst collectAllNLoop = (n, acc) => core.readWithCause({\n  onInput: chunk => {\n    const [collected, leftovers] = Chunk.splitAt(chunk, n);\n    if (collected.length < n) {\n      return collectAllNLoop(n - collected.length, Chunk.appendAll(acc, collected));\n    }\n    if (Chunk.isEmpty(leftovers)) {\n      return core.succeed(Chunk.appendAll(acc, collected));\n    }\n    return core.flatMap(core.write(leftovers), () => core.succeed(Chunk.appendAll(acc, collected)));\n  },\n  onFailure: core.failCause,\n  onDone: () => core.succeed(acc)\n});\n/** @internal */\nexport const collectAllFrom = self => collectAllWhileWith(self, {\n  initial: Chunk.empty(),\n  while: constTrue,\n  body: (chunk, a) => pipe(chunk, Chunk.append(a))\n});\n/** @internal */\nexport const collectAllToMap = (key, merge) => {\n  return foldLeftChunks(HashMap.empty(), (map, chunk) => pipe(chunk, Chunk.reduce(map, (map, input) => {\n    const k = key(input);\n    const v = pipe(map, HashMap.has(k)) ? merge(pipe(map, HashMap.unsafeGet(k)), input) : input;\n    return pipe(map, HashMap.set(k, v));\n  })));\n};\n/** @internal */\nexport const collectAllToMapN = (n, key, merge) => {\n  return foldWeighted({\n    initial: HashMap.empty(),\n    maxCost: n,\n    cost: (acc, input) => pipe(acc, HashMap.has(key(input))) ? 0 : 1,\n    body: (acc, input) => {\n      const k = key(input);\n      const v = pipe(acc, HashMap.has(k)) ? merge(pipe(acc, HashMap.unsafeGet(k)), input) : input;\n      return pipe(acc, HashMap.set(k, v));\n    }\n  });\n};\n/** @internal */\nexport const collectAllToSet = () => foldLeftChunks(HashSet.empty(), (acc, chunk) => pipe(chunk, Chunk.reduce(acc, (acc, input) => pipe(acc, HashSet.add(input)))));\n/** @internal */\nexport const collectAllToSetN = n => foldWeighted({\n  initial: HashSet.empty(),\n  maxCost: n,\n  cost: (acc, input) => HashSet.has(acc, input) ? 0 : 1,\n  body: (acc, input) => HashSet.add(acc, input)\n});\n/** @internal */\nexport const collectAllUntil = p => {\n  return pipe(fold([Chunk.empty(), true], tuple => tuple[1], ([chunk, _], input) => [pipe(chunk, Chunk.append(input)), !p(input)]), map(tuple => tuple[0]));\n};\n/** @internal */\nexport const collectAllUntilEffect = p => {\n  return pipe(foldEffect([Chunk.empty(), true], tuple => tuple[1], ([chunk, _], input) => pipe(p(input), Effect.map(bool => [pipe(chunk, Chunk.append(input)), !bool]))), map(tuple => tuple[0]));\n};\n/** @internal */\nexport const collectAllWhile = predicate => fromChannel(collectAllWhileReader(predicate, Chunk.empty()));\n/** @internal */\nconst collectAllWhileReader = (predicate, done) => core.readWith({\n  onInput: input => {\n    const [collected, leftovers] = pipe(Chunk.toReadonlyArray(input), Arr.span(predicate));\n    if (leftovers.length === 0) {\n      return collectAllWhileReader(predicate, pipe(done, Chunk.appendAll(Chunk.unsafeFromArray(collected))));\n    }\n    return pipe(core.write(Chunk.unsafeFromArray(leftovers)), channel.zipRight(core.succeed(pipe(done, Chunk.appendAll(Chunk.unsafeFromArray(collected))))));\n  },\n  onFailure: core.fail,\n  onDone: () => core.succeed(done)\n});\n/** @internal */\nexport const collectAllWhileEffect = predicate => fromChannel(collectAllWhileEffectReader(predicate, Chunk.empty()));\n/** @internal */\nconst collectAllWhileEffectReader = (predicate, done) => core.readWith({\n  onInput: input => pipe(core.fromEffect(pipe(input, Effect.takeWhile(predicate), Effect.map(Chunk.unsafeFromArray))), core.flatMap(collected => {\n    const leftovers = pipe(input, Chunk.drop(collected.length));\n    if (Chunk.isEmpty(leftovers)) {\n      return collectAllWhileEffectReader(predicate, pipe(done, Chunk.appendAll(collected)));\n    }\n    return pipe(core.write(leftovers), channel.zipRight(core.succeed(pipe(done, Chunk.appendAll(collected)))));\n  })),\n  onFailure: core.fail,\n  onDone: () => core.succeed(done)\n});\n/** @internal */\nexport const collectAllWhileWith = /*#__PURE__*/dual(2, (self, options) => {\n  const refs = pipe(Ref.make(Chunk.empty()), Effect.zip(Ref.make(false)));\n  const newChannel = pipe(core.fromEffect(refs), core.flatMap(([leftoversRef, upstreamDoneRef]) => {\n    const upstreamMarker = core.readWith({\n      onInput: input => pipe(core.write(input), core.flatMap(() => upstreamMarker)),\n      onFailure: core.fail,\n      onDone: done => pipe(core.fromEffect(Ref.set(upstreamDoneRef, true)), channel.as(done))\n    });\n    return pipe(upstreamMarker, core.pipeTo(channel.bufferChunk(leftoversRef)), core.pipeTo(collectAllWhileWithLoop(self, leftoversRef, upstreamDoneRef, options.initial, options.while, options.body)));\n  }));\n  return new SinkImpl(newChannel);\n});\nconst collectAllWhileWithLoop = (self, leftoversRef, upstreamDoneRef, currentResult, p, f) => {\n  return pipe(toChannel(self), channel.doneCollect, channel.foldChannel({\n    onFailure: core.fail,\n    onSuccess: ([leftovers, doneValue]) => p(doneValue) ? pipe(core.fromEffect(Ref.set(leftoversRef, Chunk.flatten(leftovers))), core.flatMap(() => pipe(core.fromEffect(Ref.get(upstreamDoneRef)), core.flatMap(upstreamDone => {\n      const accumulatedResult = f(currentResult, doneValue);\n      return upstreamDone ? pipe(core.write(Chunk.flatten(leftovers)), channel.as(accumulatedResult)) : collectAllWhileWithLoop(self, leftoversRef, upstreamDoneRef, accumulatedResult, p, f);\n    })))) : pipe(core.write(Chunk.flatten(leftovers)), channel.as(currentResult))\n  }));\n};\n/** @internal */\nexport const collectLeftover = self => new SinkImpl(pipe(core.collectElements(toChannel(self)), channel.map(([chunks, z]) => [z, Chunk.flatten(chunks)])));\n/** @internal */\nexport const mapInput = /*#__PURE__*/dual(2, (self, f) => pipe(self, mapInputChunks(Chunk.map(f))));\n/** @internal */\nexport const mapInputEffect = /*#__PURE__*/dual(2, (self, f) => mapInputChunksEffect(self, chunk => Effect.map(Effect.forEach(chunk, v => f(v)), Chunk.unsafeFromArray)));\n/** @internal */\nexport const mapInputChunks = /*#__PURE__*/dual(2, (self, f) => {\n  const loop = core.readWith({\n    onInput: chunk => pipe(core.write(f(chunk)), core.flatMap(() => loop)),\n    onFailure: core.fail,\n    onDone: core.succeed\n  });\n  return new SinkImpl(pipe(loop, core.pipeTo(toChannel(self))));\n});\n/** @internal */\nexport const mapInputChunksEffect = /*#__PURE__*/dual(2, (self, f) => {\n  const loop = core.readWith({\n    onInput: chunk => pipe(core.fromEffect(f(chunk)), core.flatMap(core.write), core.flatMap(() => loop)),\n    onFailure: core.fail,\n    onDone: core.succeed\n  });\n  return new SinkImpl(pipe(loop, channel.pipeToOrFail(toChannel(self))));\n});\n/** @internal */\nexport const die = defect => failCause(Cause.die(defect));\n/** @internal */\nexport const dieMessage = message => failCause(Cause.die(new Cause.RuntimeException(message)));\n/** @internal */\nexport const dieSync = evaluate => failCauseSync(() => Cause.die(evaluate()));\n/** @internal */\nexport const dimap = /*#__PURE__*/dual(2, (self, options) => map(mapInput(self, options.onInput), options.onDone));\n/** @internal */\nexport const dimapEffect = /*#__PURE__*/dual(2, (self, options) => mapEffect(mapInputEffect(self, options.onInput), options.onDone));\n/** @internal */\nexport const dimapChunks = /*#__PURE__*/dual(2, (self, options) => map(mapInputChunks(self, options.onInput), options.onDone));\n/** @internal */\nexport const dimapChunksEffect = /*#__PURE__*/dual(2, (self, options) => mapEffect(mapInputChunksEffect(self, options.onInput), options.onDone));\n/** @internal */\nexport const drain = /*#__PURE__*/new SinkImpl(/*#__PURE__*/channel.drain(/*#__PURE__*/channel.identityChannel()));\n/** @internal */\nexport const drop = n => suspend(() => new SinkImpl(dropLoop(n)));\n/** @internal */\nconst dropLoop = n => core.readWith({\n  onInput: input => {\n    const dropped = pipe(input, Chunk.drop(n));\n    const leftover = Math.max(n - input.length, 0);\n    const more = Chunk.isEmpty(input) || leftover > 0;\n    if (more) {\n      return dropLoop(leftover);\n    }\n    return pipe(core.write(dropped), channel.zipRight(channel.identityChannel()));\n  },\n  onFailure: core.fail,\n  onDone: () => core.void\n});\n/** @internal */\nexport const dropUntil = predicate => new SinkImpl(pipe(toChannel(dropWhile(input => !predicate(input))), channel.pipeToOrFail(toChannel(drop(1)))));\n/** @internal */\nexport const dropUntilEffect = predicate => suspend(() => new SinkImpl(dropUntilEffectReader(predicate)));\n/** @internal */\nconst dropUntilEffectReader = predicate => core.readWith({\n  onInput: input => pipe(input, Effect.dropUntil(predicate), Effect.map(leftover => {\n    const more = leftover.length === 0;\n    return more ? dropUntilEffectReader(predicate) : pipe(core.write(Chunk.unsafeFromArray(leftover)), channel.zipRight(channel.identityChannel()));\n  }), channel.unwrap),\n  onFailure: core.fail,\n  onDone: () => core.void\n});\n/** @internal */\nexport const dropWhile = predicate => new SinkImpl(dropWhileReader(predicate));\n/** @internal */\nconst dropWhileReader = predicate => core.readWith({\n  onInput: input => {\n    const out = pipe(input, Chunk.dropWhile(predicate));\n    if (Chunk.isEmpty(out)) {\n      return dropWhileReader(predicate);\n    }\n    return pipe(core.write(out), channel.zipRight(channel.identityChannel()));\n  },\n  onFailure: core.fail,\n  onDone: core.succeedNow\n});\n/** @internal */\nexport const dropWhileEffect = predicate => suspend(() => new SinkImpl(dropWhileEffectReader(predicate)));\n/** @internal */\nconst dropWhileEffectReader = predicate => core.readWith({\n  onInput: input => pipe(input, Effect.dropWhile(predicate), Effect.map(leftover => {\n    const more = leftover.length === 0;\n    return more ? dropWhileEffectReader(predicate) : pipe(core.write(Chunk.unsafeFromArray(leftover)), channel.zipRight(channel.identityChannel()));\n  }), channel.unwrap),\n  onFailure: core.fail,\n  onDone: () => core.void\n});\n/** @internal */\nexport const ensuring = /*#__PURE__*/dual(2, (self, finalizer) => new SinkImpl(pipe(self, toChannel, channel.ensuring(finalizer))));\n/** @internal */\nexport const ensuringWith = /*#__PURE__*/dual(2, (self, finalizer) => new SinkImpl(pipe(self, toChannel, core.ensuringWith(finalizer))));\n/** @internal */\nexport const context = () => fromEffect(Effect.context());\n/** @internal */\nexport const contextWith = f => pipe(context(), map(f));\n/** @internal */\nexport const contextWithEffect = f => pipe(context(), mapEffect(f));\n/** @internal */\nexport const contextWithSink = f => new SinkImpl(channel.unwrap(Effect.contextWith(context => toChannel(f(context)))));\n/** @internal */\nexport const every = predicate => fold(true, identity, (acc, input) => acc && predicate(input));\n/** @internal */\nexport const fail = e => new SinkImpl(core.fail(e));\n/** @internal */\nexport const failSync = evaluate => new SinkImpl(core.failSync(evaluate));\n/** @internal */\nexport const failCause = cause => new SinkImpl(core.failCause(cause));\n/** @internal */\nexport const failCauseSync = evaluate => new SinkImpl(core.failCauseSync(evaluate));\n/** @internal */\nexport const filterInput = f => {\n  return self => pipe(self, mapInputChunks(Chunk.filter(f)));\n};\n/** @internal */\nexport const filterInputEffect = /*#__PURE__*/dual(2, (self, f) => mapInputChunksEffect(self, chunk => Effect.map(Effect.filter(chunk, f), Chunk.unsafeFromArray)));\n/** @internal */\nexport const findEffect = /*#__PURE__*/dual(2, (self, f) => {\n  const newChannel = pipe(core.fromEffect(pipe(Ref.make(Chunk.empty()), Effect.zip(Ref.make(false)))), core.flatMap(([leftoversRef, upstreamDoneRef]) => {\n    const upstreamMarker = core.readWith({\n      onInput: input => pipe(core.write(input), core.flatMap(() => upstreamMarker)),\n      onFailure: core.fail,\n      onDone: done => pipe(core.fromEffect(Ref.set(upstreamDoneRef, true)), channel.as(done))\n    });\n    const loop = channel.foldChannel(core.collectElements(toChannel(self)), {\n      onFailure: core.fail,\n      onSuccess: ([leftovers, doneValue]) => pipe(core.fromEffect(f(doneValue)), core.flatMap(satisfied => pipe(core.fromEffect(Ref.set(leftoversRef, Chunk.flatten(leftovers))), channel.zipRight(pipe(core.fromEffect(Ref.get(upstreamDoneRef)), core.flatMap(upstreamDone => {\n        if (satisfied) {\n          return pipe(core.write(Chunk.flatten(leftovers)), channel.as(Option.some(doneValue)));\n        }\n        if (upstreamDone) {\n          return pipe(core.write(Chunk.flatten(leftovers)), channel.as(Option.none()));\n        }\n        return loop;\n      }))))))\n    });\n    return pipe(upstreamMarker, core.pipeTo(channel.bufferChunk(leftoversRef)), core.pipeTo(loop));\n  }));\n  return new SinkImpl(newChannel);\n});\n/** @internal */\nexport const fold = (s, contFn, f) => suspend(() => new SinkImpl(foldReader(s, contFn, f)));\n/** @internal */\nconst foldReader = (s, contFn, f) => {\n  if (!contFn(s)) {\n    return core.succeedNow(s);\n  }\n  return core.readWith({\n    onInput: input => {\n      const [nextS, leftovers] = foldChunkSplit(s, input, contFn, f, 0, input.length);\n      if (Chunk.isNonEmpty(leftovers)) {\n        return pipe(core.write(leftovers), channel.as(nextS));\n      }\n      return foldReader(nextS, contFn, f);\n    },\n    onFailure: core.fail,\n    onDone: () => core.succeedNow(s)\n  });\n};\n/** @internal */\nconst foldChunkSplit = (s, chunk, contFn, f, index, length) => {\n  if (index === length) {\n    return [s, Chunk.empty()];\n  }\n  const s1 = f(s, pipe(chunk, Chunk.unsafeGet(index)));\n  if (contFn(s1)) {\n    return foldChunkSplit(s1, chunk, contFn, f, index + 1, length);\n  }\n  return [s1, pipe(chunk, Chunk.drop(index + 1))];\n};\n/** @internal */\nexport const foldSink = /*#__PURE__*/dual(2, (self, options) => {\n  const newChannel = pipe(toChannel(self), core.collectElements, channel.foldChannel({\n    onFailure: error => toChannel(options.onFailure(error)),\n    onSuccess: ([leftovers, z]) => core.suspend(() => {\n      const leftoversRef = {\n        ref: pipe(leftovers, Chunk.filter(Chunk.isNonEmpty))\n      };\n      const refReader = pipe(core.sync(() => {\n        const ref = leftoversRef.ref;\n        leftoversRef.ref = Chunk.empty();\n        return ref;\n      }),\n      // This cast is safe because of the L1 >: L <: In1 bound. It follows that\n      // L <: In1 and therefore Chunk[L] can be safely cast to Chunk[In1].\n      core.flatMap(chunk => channel.writeChunk(chunk)));\n      const passthrough = channel.identityChannel();\n      const continuationSink = pipe(refReader, channel.zipRight(passthrough), core.pipeTo(toChannel(options.onSuccess(z))));\n      return core.flatMap(core.collectElements(continuationSink), ([newLeftovers, z1]) => pipe(core.succeed(leftoversRef.ref), core.flatMap(channel.writeChunk), channel.zipRight(channel.writeChunk(newLeftovers)), channel.as(z1)));\n    })\n  }));\n  return new SinkImpl(newChannel);\n});\n/** @internal */\nexport const foldChunks = (s, contFn, f) => suspend(() => new SinkImpl(foldChunksReader(s, contFn, f)));\n/** @internal */\nconst foldChunksReader = (s, contFn, f) => {\n  if (!contFn(s)) {\n    return core.succeedNow(s);\n  }\n  return core.readWith({\n    onInput: input => foldChunksReader(f(s, input), contFn, f),\n    onFailure: core.fail,\n    onDone: () => core.succeedNow(s)\n  });\n};\n/** @internal */\nexport const foldChunksEffect = (s, contFn, f) => suspend(() => new SinkImpl(foldChunksEffectReader(s, contFn, f)));\n/** @internal */\nconst foldChunksEffectReader = (s, contFn, f) => {\n  if (!contFn(s)) {\n    return core.succeedNow(s);\n  }\n  return core.readWith({\n    onInput: input => pipe(core.fromEffect(f(s, input)), core.flatMap(s => foldChunksEffectReader(s, contFn, f))),\n    onFailure: core.fail,\n    onDone: () => core.succeedNow(s)\n  });\n};\n/** @internal */\nexport const foldEffect = (s, contFn, f) => suspend(() => new SinkImpl(foldEffectReader(s, contFn, f)));\n/** @internal */\nconst foldEffectReader = (s, contFn, f) => {\n  if (!contFn(s)) {\n    return core.succeedNow(s);\n  }\n  return core.readWith({\n    onInput: input => pipe(core.fromEffect(foldChunkSplitEffect(s, input, contFn, f)), core.flatMap(([nextS, leftovers]) => pipe(leftovers, Option.match({\n      onNone: () => foldEffectReader(nextS, contFn, f),\n      onSome: leftover => pipe(core.write(leftover), channel.as(nextS))\n    })))),\n    onFailure: core.fail,\n    onDone: () => core.succeedNow(s)\n  });\n};\n/** @internal */\nconst foldChunkSplitEffect = (s, chunk, contFn, f) => foldChunkSplitEffectInternal(s, chunk, 0, chunk.length, contFn, f);\n/** @internal */\nconst foldChunkSplitEffectInternal = (s, chunk, index, length, contFn, f) => {\n  if (index === length) {\n    return Effect.succeed([s, Option.none()]);\n  }\n  return pipe(f(s, pipe(chunk, Chunk.unsafeGet(index))), Effect.flatMap(s1 => contFn(s1) ? foldChunkSplitEffectInternal(s1, chunk, index + 1, length, contFn, f) : Effect.succeed([s1, Option.some(pipe(chunk, Chunk.drop(index + 1)))])));\n};\n/** @internal */\nexport const foldLeft = (s, f) => ignoreLeftover(fold(s, constTrue, f));\n/** @internal */\nexport const foldLeftChunks = (s, f) => foldChunks(s, constTrue, f);\n/** @internal */\nexport const foldLeftChunksEffect = (s, f) => ignoreLeftover(foldChunksEffect(s, constTrue, f));\n/** @internal */\nexport const foldLeftEffect = (s, f) => foldEffect(s, constTrue, f);\n/** @internal */\nexport const foldUntil = (s, max, f) => pipe(fold([s, 0], tuple => tuple[1] < max, ([output, count], input) => [f(output, input), count + 1]), map(tuple => tuple[0]));\n/** @internal */\nexport const foldUntilEffect = (s, max, f) => pipe(foldEffect([s, 0], tuple => tuple[1] < max, ([output, count], input) => pipe(f(output, input), Effect.map(s => [s, count + 1]))), map(tuple => tuple[0]));\n/** @internal */\nexport const foldWeighted = options => foldWeightedDecompose({\n  ...options,\n  decompose: Chunk.of\n});\n/** @internal */\nexport const foldWeightedDecompose = options => suspend(() => new SinkImpl(foldWeightedDecomposeLoop(options.initial, 0, false, options.maxCost, options.cost, options.decompose, options.body)));\n/** @internal */\nconst foldWeightedDecomposeLoop = (s, cost, dirty, max, costFn, decompose, f) => core.readWith({\n  onInput: input => {\n    const [nextS, nextCost, nextDirty, leftovers] = foldWeightedDecomposeFold(input, s, cost, dirty, max, costFn, decompose, f);\n    if (Chunk.isNonEmpty(leftovers)) {\n      return pipe(core.write(leftovers), channel.zipRight(core.succeedNow(nextS)));\n    }\n    if (cost > max) {\n      return core.succeedNow(nextS);\n    }\n    return foldWeightedDecomposeLoop(nextS, nextCost, nextDirty, max, costFn, decompose, f);\n  },\n  onFailure: core.fail,\n  onDone: () => core.succeedNow(s)\n});\n/** @internal */\nconst foldWeightedDecomposeFold = (input, s, cost, dirty, max, costFn, decompose, f) => {\n  for (let index = 0; index < input.length; index++) {\n    const elem = Chunk.unsafeGet(input, index);\n    const prevCost = cost;\n    cost = cost + costFn(s, elem);\n    if (cost <= max) {\n      s = f(s, elem);\n      dirty = true;\n      continue;\n    }\n    const decomposed = decompose(elem);\n    if (decomposed.length <= 1 && !dirty) {\n      // If `elem` cannot be decomposed, we need to cross the `max` threshold. To\n      // minimize \"injury\", we only allow this when we haven't added anything else\n      // to the aggregate (dirty = false).\n      return [f(s, elem), cost, true, Chunk.drop(input, index + 1)];\n    }\n    if (decomposed.length <= 1 && dirty) {\n      // If the state is dirty and `elem` cannot be decomposed, we stop folding\n      // and include `elem` in the leftovers.\n      return [s, prevCost, dirty, Chunk.drop(input, index)];\n    }\n    // `elem` got decomposed, so we will recurse with the decomposed elements pushed\n    // into the chunk we're processing and see if we can aggregate further.\n    input = Chunk.appendAll(decomposed, Chunk.drop(input, index + 1));\n    cost = prevCost;\n    index = -1;\n  }\n  return [s, cost, dirty, Chunk.empty()];\n};\n/** @internal */\nexport const foldWeightedDecomposeEffect = options => suspend(() => new SinkImpl(foldWeightedDecomposeEffectLoop(options.initial, options.maxCost, options.cost, options.decompose, options.body, 0, false)));\n/** @internal */\nexport const foldWeightedEffect = options => foldWeightedDecomposeEffect({\n  ...options,\n  decompose: input => Effect.succeed(Chunk.of(input))\n});\nconst foldWeightedDecomposeEffectLoop = (s, max, costFn, decompose, f, cost, dirty) => core.readWith({\n  onInput: input => pipe(core.fromEffect(foldWeightedDecomposeEffectFold(s, max, costFn, decompose, f, input, dirty, cost, 0)), core.flatMap(([nextS, nextCost, nextDirty, leftovers]) => {\n    if (Chunk.isNonEmpty(leftovers)) {\n      return pipe(core.write(leftovers), channel.zipRight(core.succeedNow(nextS)));\n    }\n    if (cost > max) {\n      return core.succeedNow(nextS);\n    }\n    return foldWeightedDecomposeEffectLoop(nextS, max, costFn, decompose, f, nextCost, nextDirty);\n  })),\n  onFailure: core.fail,\n  onDone: () => core.succeedNow(s)\n});\n/** @internal */\nconst foldWeightedDecomposeEffectFold = (s, max, costFn, decompose, f, input, dirty, cost, index) => {\n  if (index === input.length) {\n    return Effect.succeed([s, cost, dirty, Chunk.empty()]);\n  }\n  const elem = pipe(input, Chunk.unsafeGet(index));\n  return pipe(costFn(s, elem), Effect.map(newCost => cost + newCost), Effect.flatMap(total => {\n    if (total <= max) {\n      return pipe(f(s, elem), Effect.flatMap(s => foldWeightedDecomposeEffectFold(s, max, costFn, decompose, f, input, true, total, index + 1)));\n    }\n    return pipe(decompose(elem), Effect.flatMap(decomposed => {\n      if (decomposed.length <= 1 && !dirty) {\n        // If `elem` cannot be decomposed, we need to cross the `max` threshold. To\n        // minimize \"injury\", we only allow this when we haven't added anything else\n        // to the aggregate (dirty = false).\n        return pipe(f(s, elem), Effect.map(s => [s, total, true, pipe(input, Chunk.drop(index + 1))]));\n      }\n      if (decomposed.length <= 1 && dirty) {\n        // If the state is dirty and `elem` cannot be decomposed, we stop folding\n        // and include `elem` in th leftovers.\n        return Effect.succeed([s, cost, dirty, pipe(input, Chunk.drop(index))]);\n      }\n      // `elem` got decomposed, so we will recurse with the decomposed elements pushed\n      // into the chunk we're processing and see if we can aggregate further.\n      const next = pipe(decomposed, Chunk.appendAll(pipe(input, Chunk.drop(index + 1))));\n      return foldWeightedDecomposeEffectFold(s, max, costFn, decompose, f, next, dirty, cost, 0);\n    }));\n  }));\n};\n/** @internal */\nexport const flatMap = /*#__PURE__*/dual(2, (self, f) => foldSink(self, {\n  onFailure: fail,\n  onSuccess: f\n}));\n/** @internal */\nexport const forEach = f => {\n  const process = core.readWithCause({\n    onInput: input => pipe(core.fromEffect(Effect.forEach(input, v => f(v), {\n      discard: true\n    })), core.flatMap(() => process)),\n    onFailure: core.failCause,\n    onDone: () => core.void\n  });\n  return new SinkImpl(process);\n};\n/** @internal */\nexport const forEachChunk = f => {\n  const process = core.readWithCause({\n    onInput: input => pipe(core.fromEffect(f(input)), core.flatMap(() => process)),\n    onFailure: core.failCause,\n    onDone: () => core.void\n  });\n  return new SinkImpl(process);\n};\n/** @internal */\nexport const forEachWhile = f => {\n  const process = core.readWithCause({\n    onInput: input => forEachWhileReader(f, input, 0, input.length, process),\n    onFailure: core.failCause,\n    onDone: () => core.void\n  });\n  return new SinkImpl(process);\n};\n/** @internal */\nconst forEachWhileReader = (f, input, index, length, cont) => {\n  if (index === length) {\n    return cont;\n  }\n  return pipe(core.fromEffect(f(pipe(input, Chunk.unsafeGet(index)))), core.flatMap(bool => bool ? forEachWhileReader(f, input, index + 1, length, cont) : core.write(pipe(input, Chunk.drop(index)))), channel.catchAll(error => pipe(core.write(pipe(input, Chunk.drop(index))), channel.zipRight(core.fail(error)))));\n};\n/** @internal */\nexport const forEachChunkWhile = f => {\n  const reader = core.readWith({\n    onInput: input => pipe(core.fromEffect(f(input)), core.flatMap(cont => cont ? reader : core.void)),\n    onFailure: core.fail,\n    onDone: () => core.void\n  });\n  return new SinkImpl(reader);\n};\n/** @internal */\nexport const fromChannel = channel => new SinkImpl(channel);\n/** @internal */\nexport const fromEffect = effect => new SinkImpl(core.fromEffect(effect));\n/** @internal */\nexport const fromPubSub = (pubsub, options) => fromQueue(pubsub, options);\n/** @internal */\nexport const fromPush = push => new SinkImpl(channel.unwrapScoped(pipe(push, Effect.map(fromPushPull))));\nconst fromPushPull = push => core.readWith({\n  onInput: input => channel.foldChannel(core.fromEffect(push(Option.some(input))), {\n    onFailure: ([either, leftovers]) => Either.match(either, {\n      onLeft: error => pipe(core.write(leftovers), channel.zipRight(core.fail(error))),\n      onRight: z => pipe(core.write(leftovers), channel.zipRight(core.succeedNow(z)))\n    }),\n    onSuccess: () => fromPushPull(push)\n  }),\n  onFailure: core.fail,\n  onDone: () => channel.foldChannel(core.fromEffect(push(Option.none())), {\n    onFailure: ([either, leftovers]) => Either.match(either, {\n      onLeft: error => pipe(core.write(leftovers), channel.zipRight(core.fail(error))),\n      onRight: z => pipe(core.write(leftovers), channel.zipRight(core.succeedNow(z)))\n    }),\n    onSuccess: () => core.fromEffect(Effect.dieMessage(\"BUG: Sink.fromPush - please report an issue at https://github.com/Effect-TS/effect/issues\"))\n  })\n});\n/** @internal */\nexport const fromQueue = (queue, options) => options?.shutdown ? unwrapScoped(Effect.map(Effect.acquireRelease(Effect.succeed(queue), Queue.shutdown), fromQueue)) : forEachChunk(input => Queue.offerAll(queue, input));\n/** @internal */\nexport const head = () => fold(Option.none(), Option.isNone, (option, input) => Option.match(option, {\n  onNone: () => Option.some(input),\n  onSome: () => option\n}));\n/** @internal */\nexport const ignoreLeftover = self => new SinkImpl(channel.drain(toChannel(self)));\n/** @internal */\nexport const last = () => foldLeftChunks(Option.none(), (s, input) => Option.orElse(Chunk.last(input), () => s));\n/** @internal */\nexport const leftover = chunk => new SinkImpl(core.suspend(() => core.write(chunk)));\n/** @internal */\nexport const map = /*#__PURE__*/dual(2, (self, f) => {\n  return new SinkImpl(pipe(toChannel(self), channel.map(f)));\n});\n/** @internal */\nexport const mapEffect = /*#__PURE__*/dual(2, (self, f) => new SinkImpl(pipe(toChannel(self), channel.mapEffect(f))));\n/** @internal */\nexport const mapError = /*#__PURE__*/dual(2, (self, f) => new SinkImpl(pipe(toChannel(self), channel.mapError(f))));\n/** @internal */\nexport const mapLeftover = /*#__PURE__*/dual(2, (self, f) => new SinkImpl(pipe(toChannel(self), channel.mapOut(Chunk.map(f)))));\n/** @internal */\nexport const never = /*#__PURE__*/fromEffect(Effect.never);\n/** @internal */\nexport const orElse = /*#__PURE__*/dual(2, (self, that) => new SinkImpl(pipe(toChannel(self), channel.orElse(() => toChannel(that())))));\n/** @internal */\nexport const provideContext = /*#__PURE__*/dual(2, (self, context) => new SinkImpl(pipe(toChannel(self), core.provideContext(context))));\n/** @internal */\nexport const race = /*#__PURE__*/dual(2, (self, that) => pipe(self, raceBoth(that), map(Either.merge)));\n/** @internal */\nexport const raceBoth = /*#__PURE__*/dual(args => isSink(args[1]), (self, that, options) => raceWith(self, {\n  other: that,\n  onSelfDone: selfDone => mergeDecision.Done(Effect.map(selfDone, Either.left)),\n  onOtherDone: thatDone => mergeDecision.Done(Effect.map(thatDone, Either.right)),\n  capacity: options?.capacity ?? 16\n}));\n/** @internal */\nexport const raceWith = /*#__PURE__*/dual(2, (self, options) => {\n  function race(scope) {\n    return Effect.gen(function* () {\n      const pubsub = yield* PubSub.bounded(options?.capacity ?? 16);\n      const subscription1 = yield* Scope.extend(PubSub.subscribe(pubsub), scope);\n      const subscription2 = yield* Scope.extend(PubSub.subscribe(pubsub), scope);\n      const reader = channel.toPubSub(pubsub);\n      const writer = channel.fromQueue(subscription1).pipe(core.pipeTo(toChannel(self)), channel.zipLeft(core.fromEffect(Queue.shutdown(subscription1))), channel.mergeWith({\n        other: channel.fromQueue(subscription2).pipe(core.pipeTo(toChannel(options.other)), channel.zipLeft(core.fromEffect(Queue.shutdown(subscription2)))),\n        onSelfDone: options.onSelfDone,\n        onOtherDone: options.onOtherDone\n      }));\n      const racedChannel = channel.mergeWith(reader, {\n        other: writer,\n        onSelfDone: () => mergeDecision.Await(identity),\n        onOtherDone: exit => mergeDecision.Done(exit)\n      });\n      return new SinkImpl(racedChannel);\n    });\n  }\n  return unwrapScopedWith(race);\n});\n/** @internal */\nexport const refineOrDie = /*#__PURE__*/dual(2, (self, pf) => pipe(self, refineOrDieWith(pf, identity)));\n/** @internal */\nexport const refineOrDieWith = /*#__PURE__*/dual(3, (self, pf, f) => {\n  const newChannel = pipe(self, toChannel, channel.catchAll(error => Option.match(pf(error), {\n    onNone: () => core.failCauseSync(() => Cause.die(f(error))),\n    onSome: core.fail\n  })));\n  return new SinkImpl(newChannel);\n});\n/** @internal */\nexport const service = tag => serviceWith(tag, identity);\n/** @internal */\nexport const serviceWith = (tag, f) => fromEffect(Effect.map(tag, f));\n/** @internal */\nexport const serviceWithEffect = (tag, f) => fromEffect(Effect.flatMap(tag, f));\n/** @internal */\nexport const serviceWithSink = (tag, f) => new SinkImpl(pipe(Effect.map(tag, service => toChannel(f(service))), channel.unwrap));\n/** @internal */\nexport const some = predicate => fold(false, bool => !bool, (acc, input) => acc || predicate(input));\n/** @internal */\nexport const splitWhere = /*#__PURE__*/dual(2, (self, f) => {\n  const newChannel = pipe(core.fromEffect(Ref.make(Chunk.empty())), core.flatMap(ref => pipe(splitWhereSplitter(false, ref, f), channel.pipeToOrFail(toChannel(self)), core.collectElements, core.flatMap(([leftovers, z]) => pipe(core.fromEffect(Ref.get(ref)), core.flatMap(leftover => pipe(core.write(pipe(leftover, Chunk.appendAll(Chunk.flatten(leftovers)))), channel.zipRight(core.succeed(z)))))))));\n  return new SinkImpl(newChannel);\n});\n/** @internal */\nconst splitWhereSplitter = (written, leftovers, f) => core.readWithCause({\n  onInput: input => {\n    if (Chunk.isEmpty(input)) {\n      return splitWhereSplitter(written, leftovers, f);\n    }\n    if (written) {\n      const index = indexWhere(input, f);\n      if (index === -1) {\n        return channel.zipRight(core.write(input), splitWhereSplitter(true, leftovers, f));\n      }\n      const [left, right] = Chunk.splitAt(input, index);\n      return channel.zipRight(core.write(left), core.fromEffect(Ref.set(leftovers, right)));\n    }\n    const index = indexWhere(input, f, 1);\n    if (index === -1) {\n      return channel.zipRight(core.write(input), splitWhereSplitter(true, leftovers, f));\n    }\n    const [left, right] = pipe(input, Chunk.splitAt(Math.max(index, 1)));\n    return channel.zipRight(core.write(left), core.fromEffect(Ref.set(leftovers, right)));\n  },\n  onFailure: core.failCause,\n  onDone: core.succeed\n});\n/** @internal */\nconst indexWhere = (self, predicate, from = 0) => {\n  const iterator = self[Symbol.iterator]();\n  let index = 0;\n  let result = -1;\n  let next;\n  while (result < 0 && (next = iterator.next()) && !next.done) {\n    const a = next.value;\n    if (index >= from && predicate(a)) {\n      result = index;\n    }\n    index = index + 1;\n  }\n  return result;\n};\n/** @internal */\nexport const succeed = a => new SinkImpl(core.succeed(a));\n/** @internal */\nexport const sum = /*#__PURE__*/foldLeftChunks(0, (acc, chunk) => acc + Chunk.reduce(chunk, 0, (s, a) => s + a));\n/** @internal */\nexport const summarized = /*#__PURE__*/dual(3, (self, summary, f) => {\n  const newChannel = pipe(core.fromEffect(summary), core.flatMap(start => pipe(self, toChannel, core.flatMap(done => pipe(core.fromEffect(summary), channel.map(end => [done, f(start, end)]))))));\n  return new SinkImpl(newChannel);\n});\n/** @internal */\nexport const sync = evaluate => new SinkImpl(core.sync(evaluate));\n/** @internal */\nexport const take = n => pipe(foldChunks(Chunk.empty(), chunk => chunk.length < n, (acc, chunk) => pipe(acc, Chunk.appendAll(chunk))), flatMap(acc => {\n  const [taken, leftover] = pipe(acc, Chunk.splitAt(n));\n  return new SinkImpl(pipe(core.write(leftover), channel.zipRight(core.succeedNow(taken))));\n}));\n/** @internal */\nexport const toChannel = self => Effect.isEffect(self) ? toChannel(fromEffect(self)) : self.channel;\n/** @internal */\nexport const unwrap = effect => new SinkImpl(channel.unwrap(pipe(effect, Effect.map(sink => toChannel(sink)))));\n/** @internal */\nexport const unwrapScoped = effect => new SinkImpl(channel.unwrapScoped(effect.pipe(Effect.map(sink => toChannel(sink)))));\n/** @internal */\nexport const unwrapScopedWith = f => new SinkImpl(channel.unwrapScopedWith(scope => f(scope).pipe(Effect.map(sink => toChannel(sink)))));\n/** @internal */\nexport const withDuration = self => pipe(self, summarized(Clock.currentTimeMillis, (start, end) => Duration.millis(end - start)));\n/** @internal */\nexport const zip = /*#__PURE__*/dual(args => isSink(args[1]), (self, that, options) => zipWith(self, that, (z, z2) => [z, z2], options));\n/** @internal */\nexport const zipLeft = /*#__PURE__*/dual(args => isSink(args[1]), (self, that, options) => zipWith(self, that, (z, _) => z, options));\n/** @internal */\nexport const zipRight = /*#__PURE__*/dual(args => isSink(args[1]), (self, that, options) => zipWith(self, that, (_, z2) => z2, options));\n/** @internal */\nexport const zipWith = /*#__PURE__*/dual(args => isSink(args[1]), (self, that, f, options) => options?.concurrent ? raceWith(self, {\n  other: that,\n  onSelfDone: Exit.match({\n    onFailure: cause => mergeDecision.Done(Effect.failCause(cause)),\n    onSuccess: leftZ => mergeDecision.Await(Exit.match({\n      onFailure: Effect.failCause,\n      onSuccess: rightZ => Effect.succeed(f(leftZ, rightZ))\n    }))\n  }),\n  onOtherDone: Exit.match({\n    onFailure: cause => mergeDecision.Done(Effect.failCause(cause)),\n    onSuccess: rightZ => mergeDecision.Await(Exit.match({\n      onFailure: Effect.failCause,\n      onSuccess: leftZ => Effect.succeed(f(leftZ, rightZ))\n    }))\n  })\n}) : flatMap(self, z => map(that, z2 => f(z, z2))));\n// Circular with Channel\n/** @internal */\nexport const channelToSink = self => new SinkImpl(self);\n// Constants\n/** @internal */\nexport const count = /*#__PURE__*/foldLeftChunks(0, (acc, chunk) => acc + chunk.length);\n/** @internal */\nexport const mkString = /*#__PURE__*/suspend(() => {\n  const strings = [];\n  return pipe(foldLeftChunks(void 0, (_, elems) => Chunk.map(elems, elem => {\n    strings.push(String(elem));\n  })), map(() => strings.join(\"\")));\n});\n/** @internal */\nexport const timed = /*#__PURE__*/pipe(/*#__PURE__*/withDuration(drain), /*#__PURE__*/map(tuple => tuple[1]));\n//# sourceMappingURL=sink.js.map",
      "start": 1768772628588,
      "end": 1768772628588
    },
    {
      "name": "sentry-vite-component-name-annotate-plugin",
      "start": 1768772628588,
      "end": 1768772628588,
      "order": "pre"
    },
    {
      "name": "comlink",
      "start": 1768772628621,
      "end": 1768772628621,
      "order": "normal"
    },
    {
      "name": "sentry-vite-bundle-size-optimizations-plugin",
      "start": 1768772628650,
      "end": 1768772628651,
      "order": "normal"
    },
    {
      "name": "vite-plugin-csp-guard",
      "start": 1768772628706,
      "end": 1768772628706,
      "order": "post-post"
    }
  ]
}
